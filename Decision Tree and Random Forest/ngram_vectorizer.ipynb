{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RQQjn1ZREkw"
      },
      "source": [
        "## Intro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tSQ18pz8WMuB"
      },
      "outputs": [],
      "source": [
        "import numpy as np # for multi-dimensional array operations\n",
        "import pandas as pd # for reading data from .csv files\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.decomposition import PCA # for principle component analysis (dimensionality reduction)\n",
        "from sklearn.model_selection import train_test_split # for splitting the dataset into training and testing sets\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV # for getting the best hyper parameters\n",
        "from sklearn.preprocessing import MinMaxScaler # for scaling of data before PCAfrom sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score #f1 score\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3U9fplYEWbIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id                                               post  label\n",
            "0   1  not surprised liberals islamists biggest threa...      1\n",
            "1   2  liam neeson narnias aslan the lion could be mu...      0\n",
            "2   3  ur right its simple islam is not part of our c...      1\n",
            "3   4  except we dont behead queers and rape women un...      0\n",
            "4   5  pastors take note white architect designed you...      1\n",
            "5   6  im sure everyone is going to tell you how brav...      0\n",
            "6   7  its ludicrous youre hate can only produce one ...      0\n",
            "7   8  that is insane every mosque ought to be bacona...      1\n",
            "8   9  What two kinds of people are totally different...      1\n",
            "9  10  proletariat brown people bourgeoisie white people      1\n",
            "      id                                               post\n",
            "0  17185  i had some boomer cuck tell me take that pic d...\n",
            "1  17186  life of indian pm not his private choice to be...\n",
            "2  17187  diversity is only imposed on white nations div...\n",
            "3  17188  they should be in charge of their own people i...\n",
            "4  17189  white supremacists were only strong in the dem...\n",
            "5  17190  Walks into a post office to buy stamps Me Hmon...\n",
            "6  17191  seriously he fought for human rights black and...\n",
            "7  17192                              i love being white va\n",
            "8  17193                    oh wow look at this white trash\n",
            "9  17194  yes but it will go up and down were the third ...\n"
          ]
        }
      ],
      "source": [
        "train_set = pd.read_csv('../Training and Testing sets/train.csv') # import the training set\n",
        "test_set = pd.read_csv('../Training and Testing sets/test.csv') # import the testing set\n",
        "\n",
        "print(train_set.head(10))\n",
        "print(test_set.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorise the words not as one by one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                post\n",
            "0  not surprised liberals islamists biggest threa...\n",
            "1  liam neeson narnias aslan the lion could be mu...\n",
            "2  ur right its simple islam is not part of our c...\n",
            "3  except we dont behead queers and rape women un...\n",
            "4  pastors take note white architect designed you...\n",
            "5  im sure everyone is going to tell you how brav...\n",
            "6  its ludicrous youre hate can only produce one ...\n",
            "7  that is insane every mosque ought to be bacona...\n",
            "8  What two kinds of people are totally different...\n",
            "9  proletariat brown people bourgeoisie white people\n",
            "                                                post\n",
            "0  i had some boomer cuck tell me take that pic d...\n",
            "1  life of indian pm not his private choice to be...\n",
            "2  diversity is only imposed on white nations div...\n",
            "3  they should be in charge of their own people i...\n",
            "4  white supremacists were only strong in the dem...\n",
            "5  Walks into a post office to buy stamps Me Hmon...\n",
            "6  seriously he fought for human rights black and...\n",
            "7                              i love being white va\n",
            "8                    oh wow look at this white trash\n",
            "9  yes but it will go up and down were the third ...\n"
          ]
        }
      ],
      "source": [
        "train_set_label = train_set.loc[:, [\"label\"]]\n",
        "train_words = train_set.drop(['id','label'], axis =1) # train_set_features will not contain the label and id columns\n",
        "test_words = test_set.drop(['id'], axis =1)\n",
        "\n",
        "print(train_words.head(10))\n",
        "print(test_words.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21480, 2)\n",
            "                                                post  id\n",
            "0  not surprised liberals islamists biggest threa... NaN\n",
            "1  liam neeson narnias aslan the lion could be mu... NaN\n",
            "2  ur right its simple islam is not part of our c... NaN\n",
            "3  except we dont behead queers and rape women un... NaN\n",
            "4  pastors take note white architect designed you... NaN\n"
          ]
        }
      ],
      "source": [
        "frames = [train_words,test_set]\n",
        "to_vector = pd.concat(frames)\n",
        "print(to_vector.shape)\n",
        "print(to_vector.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "(21480, 151265)\n"
          ]
        }
      ],
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "to_reduce = vectorizer2.fit_transform(to_vector['post'])\n",
        "vectorizer2.get_feature_names_out()\n",
        "print(type(to_reduce))\n",
        "print(to_reduce.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21480, 174554)\n"
          ]
        }
      ],
      "source": [
        "vectorizer3 = TfidfVectorizer(analyzer='word', ngram_range=[1,2])\n",
        "to_reduce = vectorizer3.fit_transform(to_vector['post'])\n",
        "vectorizer3.get_feature_names_out()\n",
        "print(to_reduce.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVt8W7jcS1F2"
      },
      "source": [
        "## SVD (4500)\n",
        "### Used to train: X_train, Y_train \n",
        "### Used to test: X_test, Y_test (if model works well)\n",
        "Note: Validation test set separation already done in training\n",
        "\n",
        "Perform PCA on train set features and separate into x_train and y_train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRRgt96S1F-"
      },
      "source": [
        "Only explains 55%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qQuVGEV2S1F-",
        "outputId": "aa7ade23-e16e-46fa-cae2-63c10368ce6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(21480, 4500)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# perform SVD (akin to SVD on sparse matrix)\n",
        "svd = TruncatedSVD(n_components=4500, n_iter=7, random_state=42)\n",
        "traintest_reduced = svd.fit_transform(to_reduce)\n",
        "print(type(traintest_reduced))\n",
        "traintest_reduced = pd.DataFrame(data = traintest_reduced)\n",
        "traintest_reduced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5081093632987366\n"
          ]
        }
      ],
      "source": [
        "print(svd.explained_variance_ratio_.sum())  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17184, 4500)\n",
            "(17184, 1)\n",
            "(4296, 4500)\n"
          ]
        }
      ],
      "source": [
        "X = traintest_reduced.iloc[0:17184,:]\n",
        "Y = train_set_label\n",
        "submit_set_reduced = traintest_reduced.iloc[17184:,:]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(submit_set_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2cD2b8JS1F_",
        "outputId": "7477530c-491d-42ee-b04d-dc037d963451"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.15, random_state=41)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IzV0tNiSeQy"
      },
      "source": [
        "## Random Forest Rough Tuning\n",
        "\n",
        "4500 features SVD \n",
        "\n",
        "{'n_estimators': [10, 580, 1150, 1720, 2290, 2860, 3430, 4000], 'max_features': ['auto', 'sqrt'], 'max_depth': [100, 142, 185, 228, 271, 314, 357, 400], 'bootstrap': [True, False]}\n",
        "\n",
        "\n",
        "3 kfolds\n",
        "\n",
        "Results on X_test:\n",
        "\n",
        "Best:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51owuaQSeQ5",
        "outputId": "75d49b27-087b-4a5a-de8d-ec4caa0dcba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 1340, 2670, 4000], 'max_features': ['auto', 'sqrt'], 'max_depth': [100, 200, 300, 400], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 4000, num =4)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto','sqrt']\n",
        "#Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'max_features':max_features,\n",
        "            'max_depth': max_depth,\n",
        "            'bootstrap': bootstrap }\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Cwwtq9ZYSeQ6"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0) # for 3-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbRmkEfFSeQ6",
        "outputId": "596de6a7-5de3-4b97-c5ae-fadf3ce99411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=1340; total time=33.2min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=1340; total time=33.3min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=10; total time=  31.2s\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=10; total time=  26.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=10; total time=  25.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=1340; total time=34.3min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=1340; total time=55.5min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=1340; total time=55.6min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=1340; total time=58.1min\n",
            "[CV] END bootstrap=True, max_depth=400, max_features=sqrt, n_estimators=4000; total time=102.3min\n",
            "[CV] END bootstrap=True, max_depth=400, max_features=sqrt, n_estimators=4000; total time=102.3min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=400, max_features=sqrt, n_estimators=4000; total time=106.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=2670; total time=115.5min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=sqrt, n_estimators=2670; total time=115.7min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=sqrt, n_estimators=2670; total time=116.1min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=2670; total time=116.5min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=auto, n_estimators=2670; total time=122.0min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=sqrt, n_estimators=2670; total time=122.3min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=88.6min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=90.3min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=88.1min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=124.5min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=4000; total time=111.0min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=123.3min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=4000; total time=108.2min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=128.3min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, n_estimators=4000; total time=110.2min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=4000; total time=154.5min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=4000; total time=153.9min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=4000; total time=157.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'max_features': 'auto', 'max_depth': 300, 'bootstrap': False}\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X, np.ravel(Y))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIspLVVJSeQ6"
      },
      "outputs": [],
      "source": [
        "# grid_prediction = grid.predict(X_train)\n",
        "# score = f1_score(Y_train, grid_prediction)\n",
        "# print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IzV0tNiSeQy"
      },
      "source": [
        "## Random Forest Fine Tuning\n",
        "\n",
        "4500 features SVD \n",
        "\n",
        "??????\n",
        "\n",
        "\n",
        "3 kfolds\n",
        "\n",
        "Results on X_test:\n",
        "\n",
        "Best: {'n_estimators': 5, 'max_depth': 350}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51owuaQSeQ5",
        "outputId": "75d49b27-087b-4a5a-de8d-ec4caa0dcba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [5, 253, 502, 751, 1000], 'max_depth': [250, 275, 300, 325, 350]}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 1000, num =5)]\n",
        "\n",
        "#Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(start = 250, stop = 350, num = 5)]\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'max_depth': max_depth}\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Cwwtq9ZYSeQ6"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0) # for 3-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbRmkEfFSeQ6",
        "outputId": "596de6a7-5de3-4b97-c5ae-fadf3ce99411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END ....................max_depth=275, n_estimators=253; total time= 5.1min\n",
            "[CV] END ....................max_depth=275, n_estimators=253; total time= 5.1min\n",
            "[CV] END ....................max_depth=275, n_estimators=253; total time= 5.2min\n",
            "[CV] END ....................max_depth=275, n_estimators=502; total time= 9.8min\n",
            "[CV] END ....................max_depth=275, n_estimators=502; total time= 9.8min\n",
            "[CV] END ....................max_depth=275, n_estimators=502; total time=10.1min\n",
            "[CV] END ....................max_depth=275, n_estimators=751; total time=14.7min\n",
            "[CV] END ....................max_depth=275, n_estimators=751; total time=14.7min\n",
            "[CV] END ......................max_depth=350, n_estimators=5; total time=   7.9s\n",
            "[CV] END ......................max_depth=350, n_estimators=5; total time=   8.1s\n",
            "[CV] END ......................max_depth=350, n_estimators=5; total time=   7.4s\n",
            "[CV] END ....................max_depth=275, n_estimators=751; total time=15.2min\n",
            "[CV] END ...................max_depth=325, n_estimators=1000; total time=19.8min\n",
            "[CV] END ...................max_depth=325, n_estimators=1000; total time=19.9min\n",
            "[CV] END ......................max_depth=275, n_estimators=5; total time=   8.2s\n",
            "[CV] END ......................max_depth=275, n_estimators=5; total time=   8.1s\n",
            "[CV] END ......................max_depth=275, n_estimators=5; total time=   8.4s\n",
            "[CV] END ......................max_depth=250, n_estimators=5; total time=   7.4s\n",
            "[CV] END ......................max_depth=250, n_estimators=5; total time=   7.2s\n",
            "[CV] END ......................max_depth=250, n_estimators=5; total time=   7.3s\n",
            "[CV] END ...................max_depth=325, n_estimators=1000; total time=20.4min\n",
            "[CV] END ...................max_depth=275, n_estimators=1000; total time=19.1min\n",
            "[CV] END ...................max_depth=275, n_estimators=1000; total time=19.0min\n",
            "[CV] END ....................max_depth=325, n_estimators=502; total time= 9.4min\n",
            "[CV] END ....................max_depth=325, n_estimators=502; total time= 9.2min\n",
            "[CV] END ....................max_depth=325, n_estimators=502; total time= 9.6min\n",
            "[CV] END ...................max_depth=275, n_estimators=1000; total time=19.5min\n",
            "[CV] END ...................max_depth=250, n_estimators=1000; total time=17.1min\n",
            "[CV] END ...................max_depth=250, n_estimators=1000; total time=16.9min\n",
            "[CV] END ...................max_depth=250, n_estimators=1000; total time=17.4min\n",
            "{'n_estimators': 5, 'max_depth': 350}\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X, np.ravel(Y))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIspLVVJSeQ6"
      },
      "outputs": [],
      "source": [
        "# grid_prediction = grid.predict(X_train)\n",
        "# score = f1_score(Y_train, grid_prediction)\n",
        "# print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPlo0_RxRQ3y"
      },
      "source": [
        "# TO SUBMIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vk7wtjcca4_r"
      },
      "outputs": [],
      "source": [
        "y_predicted = grid.predict(submit_set_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w7z46Ug8a6Ab"
      },
      "outputs": [],
      "source": [
        "# y_predicted = svc_model.predict(test_set_features)\n",
        "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
        "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
        "y_predicted.to_csv('skynet_submission3.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "50.0007 ML 1D",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
