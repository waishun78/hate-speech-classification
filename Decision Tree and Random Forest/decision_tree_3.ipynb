{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RQQjn1ZREkw"
      },
      "source": [
        "## Intro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tSQ18pz8WMuB"
      },
      "outputs": [],
      "source": [
        "import numpy as np # for multi-dimensional array operations\n",
        "import pandas as pd # for reading data from .csv files\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.decomposition import PCA # for principle component analysis (dimensionality reduction)\n",
        "from sklearn.model_selection import train_test_split # for splitting the dataset into training and testing sets\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV # for getting the best hyper parameters\n",
        "from sklearn.preprocessing import MinMaxScaler # for scaling of data before PCAfrom sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score #f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3U9fplYEWbIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id  label    0    1    2    3    4    5    6    7  ...  4990  4991  4992  \\\n",
            "0   1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "1   2      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "2   3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "3   4      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "4   5      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "5   6      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "6   7      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "7   8      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "8   9      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "9  10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "\n",
            "   4993  4994  4995  4996  4997  4998  4999  \n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[10 rows x 5002 columns]\n",
            "      id    0    1    2    3    4    5    6    7    8  ...  4990  4991  4992  \\\n",
            "0  17185  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "1  17186  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "2  17187  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "3  17188  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "4  17189  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "5  17190  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "6  17191  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "7  17192  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "8  17193  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "9  17194  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
            "\n",
            "   4993  4994  4995  4996  4997  4998  4999  \n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[10 rows x 5001 columns]\n"
          ]
        }
      ],
      "source": [
        "train_set = pd.read_csv('../../Training and Testing sets/train_tfidf_features.csv') # import the training set\n",
        "test_set = pd.read_csv('../../Training and Testing sets/test_tfidf_features.csv') # import the testing set\n",
        "\n",
        "print(train_set.head(10))\n",
        "print(test_set.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17184, 5000)\n",
            "(4296, 5000)\n"
          ]
        }
      ],
      "source": [
        "train_set_label = train_set.loc[:, [\"label\"]]\n",
        "features_names = [str(i) for i in range(0, 5000)]\n",
        "train_set_features = train_set.loc[:, features_names] # train_set_features will not contain the label and id columns\n",
        "test_set_features = test_set.loc[:, features_names]\n",
        "\n",
        "print(train_set_features.shape)\n",
        "print(test_set_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21480, 5000)\n"
          ]
        }
      ],
      "source": [
        "frames = [train_set_features,test_set_features]\n",
        "to_reduce = pd.concat(frames)\n",
        "print(to_reduce.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqT99KhQXO2A",
        "outputId": "4df590ce-2308-4d7e-9f91-650745edaeb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Scaling\n",
            "(21480, 5000)\n"
          ]
        }
      ],
      "source": [
        "# scale the dataset before PCA\n",
        "scaler = MinMaxScaler()\n",
        "to_reduce = scaler.fit_transform(to_reduce)\n",
        "print(\"After Scaling\")\n",
        "print(to_reduce.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoIq7v7HKl0m"
      },
      "source": [
        "## PCA (80%)\n",
        "### Used to train: X_train, Y_train \n",
        "### Used to test: X_test, Y_test (if model works well)\n",
        "Note: Validation test set separation already done in training\n",
        "\n",
        "Perform PCA on train set features and separate into x_train and y_train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b6cC-k4Js4S"
      },
      "source": [
        "Select the number of components such that the amount of variance that needs to be explained is greater than 80% percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "FGq0_llkIxuo",
        "outputId": "7a69dd0f-3e46-4cdc-9328-972671851eb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1773</th>\n",
              "      <th>1774</th>\n",
              "      <th>1775</th>\n",
              "      <th>1776</th>\n",
              "      <th>1777</th>\n",
              "      <th>1778</th>\n",
              "      <th>1779</th>\n",
              "      <th>1780</th>\n",
              "      <th>1781</th>\n",
              "      <th>1782</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.083198</td>\n",
              "      <td>-0.016048</td>\n",
              "      <td>-0.010595</td>\n",
              "      <td>-0.001965</td>\n",
              "      <td>-0.013779</td>\n",
              "      <td>-0.010989</td>\n",
              "      <td>-0.009680</td>\n",
              "      <td>-0.007520</td>\n",
              "      <td>-0.022370</td>\n",
              "      <td>-0.023418</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011568</td>\n",
              "      <td>-0.013349</td>\n",
              "      <td>-0.006594</td>\n",
              "      <td>0.004195</td>\n",
              "      <td>-0.000538</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.005406</td>\n",
              "      <td>0.005453</td>\n",
              "      <td>0.011507</td>\n",
              "      <td>0.000360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.068421</td>\n",
              "      <td>-0.043649</td>\n",
              "      <td>-0.018443</td>\n",
              "      <td>-0.008228</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>-0.043177</td>\n",
              "      <td>0.127322</td>\n",
              "      <td>0.010281</td>\n",
              "      <td>0.014349</td>\n",
              "      <td>-0.005608</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035127</td>\n",
              "      <td>0.027850</td>\n",
              "      <td>-0.011023</td>\n",
              "      <td>-0.009811</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>-0.002219</td>\n",
              "      <td>-0.006450</td>\n",
              "      <td>-0.015337</td>\n",
              "      <td>-0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.080171</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.015342</td>\n",
              "      <td>-0.008697</td>\n",
              "      <td>-0.010481</td>\n",
              "      <td>-0.057562</td>\n",
              "      <td>0.075615</td>\n",
              "      <td>0.115411</td>\n",
              "      <td>0.111499</td>\n",
              "      <td>0.070551</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>-0.007846</td>\n",
              "      <td>-0.008814</td>\n",
              "      <td>-0.001514</td>\n",
              "      <td>-0.008945</td>\n",
              "      <td>0.010647</td>\n",
              "      <td>0.002845</td>\n",
              "      <td>0.001764</td>\n",
              "      <td>0.006909</td>\n",
              "      <td>-0.001785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.028600</td>\n",
              "      <td>-0.040406</td>\n",
              "      <td>0.002784</td>\n",
              "      <td>0.007087</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>-0.031219</td>\n",
              "      <td>-0.137443</td>\n",
              "      <td>0.114581</td>\n",
              "      <td>-0.013427</td>\n",
              "      <td>0.077351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023494</td>\n",
              "      <td>-0.010312</td>\n",
              "      <td>0.016959</td>\n",
              "      <td>0.009277</td>\n",
              "      <td>0.015207</td>\n",
              "      <td>-0.007301</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>-0.008891</td>\n",
              "      <td>-0.010354</td>\n",
              "      <td>0.007742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.255054</td>\n",
              "      <td>-0.113418</td>\n",
              "      <td>-0.019237</td>\n",
              "      <td>-0.021468</td>\n",
              "      <td>-0.040033</td>\n",
              "      <td>-0.007000</td>\n",
              "      <td>-0.035960</td>\n",
              "      <td>0.008656</td>\n",
              "      <td>-0.026048</td>\n",
              "      <td>-0.003353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>0.002320</td>\n",
              "      <td>0.006176</td>\n",
              "      <td>-0.010438</td>\n",
              "      <td>-0.009482</td>\n",
              "      <td>-0.013039</td>\n",
              "      <td>-0.000114</td>\n",
              "      <td>0.000515</td>\n",
              "      <td>0.003214</td>\n",
              "      <td>0.007794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17179</th>\n",
              "      <td>0.075930</td>\n",
              "      <td>0.078879</td>\n",
              "      <td>0.167305</td>\n",
              "      <td>-0.099091</td>\n",
              "      <td>0.304845</td>\n",
              "      <td>0.037762</td>\n",
              "      <td>-0.022524</td>\n",
              "      <td>0.018488</td>\n",
              "      <td>-0.015024</td>\n",
              "      <td>-0.006992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.009611</td>\n",
              "      <td>0.006904</td>\n",
              "      <td>-0.000056</td>\n",
              "      <td>-0.010809</td>\n",
              "      <td>-0.000104</td>\n",
              "      <td>-0.001102</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>-0.002404</td>\n",
              "      <td>0.002048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17180</th>\n",
              "      <td>-0.072104</td>\n",
              "      <td>-0.019731</td>\n",
              "      <td>-0.014655</td>\n",
              "      <td>-0.005451</td>\n",
              "      <td>-0.005682</td>\n",
              "      <td>-0.012314</td>\n",
              "      <td>0.005986</td>\n",
              "      <td>-0.009017</td>\n",
              "      <td>-0.003207</td>\n",
              "      <td>-0.014674</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014893</td>\n",
              "      <td>0.021566</td>\n",
              "      <td>0.008008</td>\n",
              "      <td>-0.014403</td>\n",
              "      <td>-0.018688</td>\n",
              "      <td>-0.002211</td>\n",
              "      <td>-0.005081</td>\n",
              "      <td>-0.008327</td>\n",
              "      <td>0.003585</td>\n",
              "      <td>-0.011744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17181</th>\n",
              "      <td>0.002079</td>\n",
              "      <td>-0.041786</td>\n",
              "      <td>-0.016886</td>\n",
              "      <td>-0.008919</td>\n",
              "      <td>-0.018063</td>\n",
              "      <td>-0.020858</td>\n",
              "      <td>0.006685</td>\n",
              "      <td>-0.006916</td>\n",
              "      <td>-0.017607</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003015</td>\n",
              "      <td>0.024486</td>\n",
              "      <td>-0.007753</td>\n",
              "      <td>0.002657</td>\n",
              "      <td>-0.003067</td>\n",
              "      <td>0.017837</td>\n",
              "      <td>-0.003254</td>\n",
              "      <td>0.009121</td>\n",
              "      <td>0.006637</td>\n",
              "      <td>-0.010113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17182</th>\n",
              "      <td>0.091355</td>\n",
              "      <td>-0.055903</td>\n",
              "      <td>-0.008473</td>\n",
              "      <td>-0.017559</td>\n",
              "      <td>-0.002191</td>\n",
              "      <td>-0.013549</td>\n",
              "      <td>-0.012348</td>\n",
              "      <td>-0.003722</td>\n",
              "      <td>-0.017070</td>\n",
              "      <td>-0.010729</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.005183</td>\n",
              "      <td>0.001534</td>\n",
              "      <td>-0.001772</td>\n",
              "      <td>0.007042</td>\n",
              "      <td>-0.004696</td>\n",
              "      <td>-0.000614</td>\n",
              "      <td>0.003481</td>\n",
              "      <td>-0.000966</td>\n",
              "      <td>-0.004786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17183</th>\n",
              "      <td>-0.040612</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>-0.039986</td>\n",
              "      <td>-0.025745</td>\n",
              "      <td>-0.032479</td>\n",
              "      <td>0.004735</td>\n",
              "      <td>0.001654</td>\n",
              "      <td>0.001413</td>\n",
              "      <td>-0.004797</td>\n",
              "      <td>-0.021880</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002404</td>\n",
              "      <td>-0.005053</td>\n",
              "      <td>0.004851</td>\n",
              "      <td>-0.010200</td>\n",
              "      <td>-0.001801</td>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.011302</td>\n",
              "      <td>0.008071</td>\n",
              "      <td>-0.012613</td>\n",
              "      <td>-0.012182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17184 rows × 1783 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6     \\\n",
              "0     -0.083198 -0.016048 -0.010595 -0.001965 -0.013779 -0.010989 -0.009680   \n",
              "1     -0.068421 -0.043649 -0.018443 -0.008228 -0.000051 -0.043177  0.127322   \n",
              "2     -0.080171 -0.044642 -0.015342 -0.008697 -0.010481 -0.057562  0.075615   \n",
              "3      0.028600 -0.040406  0.002784  0.007087  0.000462 -0.031219 -0.137443   \n",
              "4      0.255054 -0.113418 -0.019237 -0.021468 -0.040033 -0.007000 -0.035960   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17179  0.075930  0.078879  0.167305 -0.099091  0.304845  0.037762 -0.022524   \n",
              "17180 -0.072104 -0.019731 -0.014655 -0.005451 -0.005682 -0.012314  0.005986   \n",
              "17181  0.002079 -0.041786 -0.016886 -0.008919 -0.018063 -0.020858  0.006685   \n",
              "17182  0.091355 -0.055903 -0.008473 -0.017559 -0.002191 -0.013549 -0.012348   \n",
              "17183 -0.040612  0.093708 -0.039986 -0.025745 -0.032479  0.004735  0.001654   \n",
              "\n",
              "           7         8         9     ...      1773      1774      1775  \\\n",
              "0     -0.007520 -0.022370 -0.023418  ... -0.011568 -0.013349 -0.006594   \n",
              "1      0.010281  0.014349 -0.005608  ... -0.035127  0.027850 -0.011023   \n",
              "2      0.115411  0.111499  0.070551  ...  0.003059 -0.007846 -0.008814   \n",
              "3      0.114581 -0.013427  0.077351  ...  0.023494 -0.010312  0.016959   \n",
              "4      0.008656 -0.026048 -0.003353  ...  0.014642  0.002320  0.006176   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17179  0.018488 -0.015024 -0.006992  ...  0.001864  0.009611  0.006904   \n",
              "17180 -0.009017 -0.003207 -0.014674  ... -0.014893  0.021566  0.008008   \n",
              "17181 -0.006916 -0.017607  0.010785  ... -0.003015  0.024486 -0.007753   \n",
              "17182 -0.003722 -0.017070 -0.010729  ...  0.000124  0.005183  0.001534   \n",
              "17183  0.001413 -0.004797 -0.021880  ... -0.002404 -0.005053  0.004851   \n",
              "\n",
              "           1776      1777      1778      1779      1780      1781      1782  \n",
              "0      0.004195 -0.000538  0.005127  0.005406  0.005453  0.011507  0.000360  \n",
              "1     -0.009811  0.004957  0.002454 -0.002219 -0.006450 -0.015337 -0.000006  \n",
              "2     -0.001514 -0.008945  0.010647  0.002845  0.001764  0.006909 -0.001785  \n",
              "3      0.009277  0.015207 -0.007301  0.003193 -0.008891 -0.010354  0.007742  \n",
              "4     -0.010438 -0.009482 -0.013039 -0.000114  0.000515  0.003214  0.007794  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "17179 -0.000056 -0.010809 -0.000104 -0.001102  0.004139 -0.002404  0.002048  \n",
              "17180 -0.014403 -0.018688 -0.002211 -0.005081 -0.008327  0.003585 -0.011744  \n",
              "17181  0.002657 -0.003067  0.017837 -0.003254  0.009121  0.006637 -0.010113  \n",
              "17182 -0.001772  0.007042 -0.004696 -0.000614  0.003481 -0.000966 -0.004786  \n",
              "17183 -0.010200 -0.001801  0.022800  0.011302  0.008071 -0.012613 -0.012182  \n",
              "\n",
              "[17184 rows x 1783 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# perform PCA\n",
        "pca = PCA(n_components = 0.80)\n",
        "train_set_reduced = pca.fit_transform(train_set_features)\n",
        "train_set_reduced = pd.DataFrame(data = train_set_reduced)\n",
        "train_set_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PebqvIoyasAe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14606, 1783)\n",
            "(2578, 1783)\n"
          ]
        }
      ],
      "source": [
        "X = train_set_reduced\n",
        "Y = train_set_label\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.15, random_state=41)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnhT4uvMKyWb"
      },
      "source": [
        "Perform PCA on test set features and separate into x_train and y_train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-6REl5mZa2XS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1773</th>\n",
              "      <th>1774</th>\n",
              "      <th>1775</th>\n",
              "      <th>1776</th>\n",
              "      <th>1777</th>\n",
              "      <th>1778</th>\n",
              "      <th>1779</th>\n",
              "      <th>1780</th>\n",
              "      <th>1781</th>\n",
              "      <th>1782</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.082801</td>\n",
              "      <td>-0.009343</td>\n",
              "      <td>-0.013543</td>\n",
              "      <td>-0.013317</td>\n",
              "      <td>-0.007984</td>\n",
              "      <td>-0.002459</td>\n",
              "      <td>-0.026278</td>\n",
              "      <td>0.004096</td>\n",
              "      <td>-0.014072</td>\n",
              "      <td>-0.020606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024957</td>\n",
              "      <td>0.024105</td>\n",
              "      <td>-0.017568</td>\n",
              "      <td>0.003822</td>\n",
              "      <td>0.008023</td>\n",
              "      <td>-0.010257</td>\n",
              "      <td>0.025428</td>\n",
              "      <td>-0.004821</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>0.016787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.075595</td>\n",
              "      <td>0.005040</td>\n",
              "      <td>-0.017771</td>\n",
              "      <td>-0.014935</td>\n",
              "      <td>-0.000467</td>\n",
              "      <td>-0.001601</td>\n",
              "      <td>-0.055948</td>\n",
              "      <td>-0.017461</td>\n",
              "      <td>-0.031185</td>\n",
              "      <td>-0.017278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008950</td>\n",
              "      <td>0.015088</td>\n",
              "      <td>-0.007169</td>\n",
              "      <td>-0.009299</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>-0.003901</td>\n",
              "      <td>-0.015390</td>\n",
              "      <td>0.009871</td>\n",
              "      <td>0.000731</td>\n",
              "      <td>-0.001370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.163876</td>\n",
              "      <td>0.059162</td>\n",
              "      <td>-0.057706</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>-0.063164</td>\n",
              "      <td>-0.003223</td>\n",
              "      <td>0.020473</td>\n",
              "      <td>-0.005967</td>\n",
              "      <td>-0.005539</td>\n",
              "      <td>-0.008680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007533</td>\n",
              "      <td>-0.003971</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.009313</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>0.002346</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>-0.000932</td>\n",
              "      <td>-0.001051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.006835</td>\n",
              "      <td>0.189357</td>\n",
              "      <td>-0.044389</td>\n",
              "      <td>-0.024452</td>\n",
              "      <td>-0.043835</td>\n",
              "      <td>-0.013077</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>-0.005021</td>\n",
              "      <td>-0.028871</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001175</td>\n",
              "      <td>-0.000238</td>\n",
              "      <td>0.002451</td>\n",
              "      <td>-0.004008</td>\n",
              "      <td>0.004178</td>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.006505</td>\n",
              "      <td>0.003388</td>\n",
              "      <td>-0.001446</td>\n",
              "      <td>0.002821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.120704</td>\n",
              "      <td>-0.089485</td>\n",
              "      <td>0.015896</td>\n",
              "      <td>0.030057</td>\n",
              "      <td>-0.018015</td>\n",
              "      <td>-0.057111</td>\n",
              "      <td>-0.072387</td>\n",
              "      <td>0.053490</td>\n",
              "      <td>-0.153091</td>\n",
              "      <td>0.026020</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000823</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>-0.005434</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>-0.003229</td>\n",
              "      <td>-0.002975</td>\n",
              "      <td>-0.000870</td>\n",
              "      <td>-0.009341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4291</th>\n",
              "      <td>-0.076808</td>\n",
              "      <td>-0.024913</td>\n",
              "      <td>-0.014752</td>\n",
              "      <td>-0.008106</td>\n",
              "      <td>-0.009817</td>\n",
              "      <td>-0.013137</td>\n",
              "      <td>0.026288</td>\n",
              "      <td>-0.012828</td>\n",
              "      <td>-0.004845</td>\n",
              "      <td>-0.010727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>-0.000223</td>\n",
              "      <td>0.006229</td>\n",
              "      <td>-0.003326</td>\n",
              "      <td>0.013008</td>\n",
              "      <td>-0.002241</td>\n",
              "      <td>-0.004073</td>\n",
              "      <td>-0.001340</td>\n",
              "      <td>-0.003943</td>\n",
              "      <td>0.006119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4292</th>\n",
              "      <td>0.069331</td>\n",
              "      <td>-0.055078</td>\n",
              "      <td>-0.008249</td>\n",
              "      <td>-0.022183</td>\n",
              "      <td>-0.000882</td>\n",
              "      <td>0.024624</td>\n",
              "      <td>-0.085988</td>\n",
              "      <td>-0.152147</td>\n",
              "      <td>0.159634</td>\n",
              "      <td>0.018128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005807</td>\n",
              "      <td>-0.012032</td>\n",
              "      <td>-0.004000</td>\n",
              "      <td>-0.001530</td>\n",
              "      <td>-0.006042</td>\n",
              "      <td>0.002616</td>\n",
              "      <td>-0.023036</td>\n",
              "      <td>-0.015403</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>0.019688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4293</th>\n",
              "      <td>0.042192</td>\n",
              "      <td>-0.056123</td>\n",
              "      <td>-0.009015</td>\n",
              "      <td>-0.022608</td>\n",
              "      <td>-0.000348</td>\n",
              "      <td>0.011589</td>\n",
              "      <td>-0.046442</td>\n",
              "      <td>-0.129357</td>\n",
              "      <td>0.126640</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011093</td>\n",
              "      <td>0.019703</td>\n",
              "      <td>0.021460</td>\n",
              "      <td>0.012654</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>-0.017409</td>\n",
              "      <td>-0.008309</td>\n",
              "      <td>-0.002952</td>\n",
              "      <td>-0.025245</td>\n",
              "      <td>-0.008260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4294</th>\n",
              "      <td>0.220417</td>\n",
              "      <td>-0.101562</td>\n",
              "      <td>-0.013420</td>\n",
              "      <td>-0.014971</td>\n",
              "      <td>-0.033857</td>\n",
              "      <td>-0.007979</td>\n",
              "      <td>-0.018445</td>\n",
              "      <td>-0.004240</td>\n",
              "      <td>-0.019587</td>\n",
              "      <td>-0.000660</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002257</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>-0.001471</td>\n",
              "      <td>-0.000596</td>\n",
              "      <td>-0.003709</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.010312</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.002554</td>\n",
              "      <td>-0.000411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4295</th>\n",
              "      <td>-0.028551</td>\n",
              "      <td>0.206733</td>\n",
              "      <td>-0.065921</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>-0.018891</td>\n",
              "      <td>0.099399</td>\n",
              "      <td>-0.046296</td>\n",
              "      <td>-0.030327</td>\n",
              "      <td>-0.082679</td>\n",
              "      <td>0.242060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004114</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>-0.002018</td>\n",
              "      <td>-0.004545</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>-0.001406</td>\n",
              "      <td>-0.006265</td>\n",
              "      <td>-0.002345</td>\n",
              "      <td>-0.000754</td>\n",
              "      <td>-0.003174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4296 rows × 1783 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6     \\\n",
              "0    -0.082801 -0.009343 -0.013543 -0.013317 -0.007984 -0.002459 -0.026278   \n",
              "1    -0.075595  0.005040 -0.017771 -0.014935 -0.000467 -0.001601 -0.055948   \n",
              "2     0.163876  0.059162 -0.057706 -0.040884 -0.063164 -0.003223  0.020473   \n",
              "3    -0.006835  0.189357 -0.044389 -0.024452 -0.043835 -0.013077  0.001344   \n",
              "4     0.120704 -0.089485  0.015896  0.030057 -0.018015 -0.057111 -0.072387   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4291 -0.076808 -0.024913 -0.014752 -0.008106 -0.009817 -0.013137  0.026288   \n",
              "4292  0.069331 -0.055078 -0.008249 -0.022183 -0.000882  0.024624 -0.085988   \n",
              "4293  0.042192 -0.056123 -0.009015 -0.022608 -0.000348  0.011589 -0.046442   \n",
              "4294  0.220417 -0.101562 -0.013420 -0.014971 -0.033857 -0.007979 -0.018445   \n",
              "4295 -0.028551  0.206733 -0.065921 -0.009538 -0.018891  0.099399 -0.046296   \n",
              "\n",
              "          7         8         9     ...      1773      1774      1775  \\\n",
              "0     0.004096 -0.014072 -0.020606  ...  0.024957  0.024105 -0.017568   \n",
              "1    -0.017461 -0.031185 -0.017278  ...  0.008950  0.015088 -0.007169   \n",
              "2    -0.005967 -0.005539 -0.008680  ...  0.007533 -0.003971  0.002672   \n",
              "3     0.000674 -0.005021 -0.028871  ... -0.001175 -0.000238  0.002451   \n",
              "4     0.053490 -0.153091  0.026020  ... -0.000823  0.002520  0.004705   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4291 -0.012828 -0.004845 -0.010727  ...  0.000180 -0.000223  0.006229   \n",
              "4292 -0.152147  0.159634  0.018128  ...  0.005807 -0.012032 -0.004000   \n",
              "4293 -0.129357  0.126640  0.010080  ...  0.011093  0.019703  0.021460   \n",
              "4294 -0.004240 -0.019587 -0.000660  ... -0.002257  0.002456 -0.001471   \n",
              "4295 -0.030327 -0.082679  0.242060  ... -0.004114 -0.004397 -0.002018   \n",
              "\n",
              "          1776      1777      1778      1779      1780      1781      1782  \n",
              "0     0.003822  0.008023 -0.010257  0.025428 -0.004821 -0.002038  0.016787  \n",
              "1    -0.009299  0.001821 -0.003901 -0.015390  0.009871  0.000731 -0.001370  \n",
              "2     0.009313  0.000310 -0.002152  0.002346  0.000066 -0.000932 -0.001051  \n",
              "3    -0.004008  0.004178  0.000616  0.006505  0.003388 -0.001446  0.002821  \n",
              "4    -0.005434  0.000582 -0.004489 -0.003229 -0.002975 -0.000870 -0.009341  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "4291 -0.003326  0.013008 -0.002241 -0.004073 -0.001340 -0.003943  0.006119  \n",
              "4292 -0.001530 -0.006042  0.002616 -0.023036 -0.015403  0.005047  0.019688  \n",
              "4293  0.012654  0.000310 -0.017409 -0.008309 -0.002952 -0.025245 -0.008260  \n",
              "4294 -0.000596 -0.003709  0.001838 -0.010312  0.000559  0.002554 -0.000411  \n",
              "4295 -0.004545  0.000819 -0.001406 -0.006265 -0.002345 -0.000754 -0.003174  \n",
              "\n",
              "[4296 rows x 1783 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_names = [str(i) for i in range(0, 5000)]\n",
        "test_set_features = test_set.loc[:, features_names] # test_set_features will not contain the label and id columns\n",
        "\n",
        "# scale the dataset before PCA\n",
        "test_set_rescaled = scaler.transform(test_set_features)\n",
        "\n",
        "# perform PCA\n",
        "submit_set_reduced = pca.transform(test_set_features) # use the pca from the train_set?\n",
        "submit_set_features = pd.DataFrame(data = submit_set_reduced)\n",
        "submit_set_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4D5pLGBODPv"
      },
      "source": [
        "# Training: \n",
        "80% variance\n",
        "\n",
        "{'n_estimators': [10, 100], 'max_features': ['log2', 'sqrt'], 'max_depth': [2, 4], 'bootstrap': [True, False]}\n",
        "\n",
        "3 kfold\n",
        "\n",
        "Results on X_test:0.0036029544226265538\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dyqrceuN1zA",
        "outputId": "fb0a3510-7397-4e8d-8098-5bc8d5093edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 100], 'max_features': ['log2', 'sqrt'], 'max_depth': [2, 4], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num =2)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['log2','sqrt']\n",
        "#Maximum number of levels in tree\n",
        "max_depth = [2,4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'max_features':max_features,\n",
        "            'max_depth': max_depth,\n",
        "            'bootstrap': bootstrap }\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oCinOTXPOl9I"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0) # for 3-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TKSGnr-a3xO",
        "outputId": "51684453-c14e-440b-ad4e-1e5eb48c173f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   3.3s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   3.4s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   3.4s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   3.6s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   3.6s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   3.7s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   1.6s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   1.6s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   1.6s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   5.4s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   5.3s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   5.4s\n",
            "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.8s\n",
            "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.8s\n",
            "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.9s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   3.6s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   3.6s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   3.6s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=100; total time=   8.9s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=100; total time=   8.9s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=100; total time=   9.0s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=100; total time=   6.9s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=100; total time=   7.0s\n",
            "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=100; total time=   7.0s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=100; total time=  11.0s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=100; total time=  11.1s\n",
            "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=100; total time=  11.2s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=100; total time=  13.5s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=100; total time=  13.5s\n",
            "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=100; total time=  13.6s\n",
            "{'n_estimators': 10, 'max_features': 'sqrt', 'max_depth': 4, 'bootstrap': True}\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X_train, np.ravel(Y_train))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqkIjZO8RWCO",
        "outputId": "807f0c8f-772c-485d-bc1d-d050ef7c86a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.041615235408217245\n"
          ]
        }
      ],
      "source": [
        "grid_prediction = grid.predict(X_train)\n",
        "score = f1_score(Y_train, grid_prediction)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiixxtVKSdEX"
      },
      "source": [
        "# Training\n",
        "\n",
        "80% variance\n",
        "\n",
        "{'n_estimators': [10, 673, 1336, 2000], 'max_features': ['auto', 'log2', 'sqrt'], 'max_depth': [10, 73, 136, 200], 'bootstrap': [True, False]}\n",
        "\n",
        "4 kfolds\n",
        "\n",
        "Results on X_test:0.9960238568588469\n",
        "\n",
        "Best: {'n_estimators': 10, 'max_features': 'sqrt', 'max_depth': 200, 'bootstrap': False}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9hKKWDCSdEY",
        "outputId": "04224804-14c4-4ed3-8eda-0ae368cf76e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 673, 1336, 2000], 'max_features': ['auto', 'log2', 'sqrt'], 'max_depth': [10, 73, 136, 200], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num =4)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto','log2','sqrt']\n",
        "#Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(start = 10, stop = 200, num = 4)]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'max_features':max_features,\n",
        "            'max_depth': max_depth,\n",
        "            'bootstrap': bootstrap }\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KEWZ21JkSdEZ"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 0) # for 4-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeCRoFjlSdEZ",
        "outputId": "11340e2e-b7b3-4145-cf4e-38e703e53769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=10, max_features=log2, n_estimators=2000; total time= 3.7min\n",
            "[CV] END bootstrap=True, max_depth=10, max_features=log2, n_estimators=2000; total time= 3.7min\n",
            "[CV] END bootstrap=True, max_depth=10, max_features=log2, n_estimators=2000; total time= 3.7min\n",
            "[CV] END bootstrap=True, max_depth=10, max_features=log2, n_estimators=2000; total time= 3.7min\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/decision_tree_3.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000021?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000021?line=1'>2</a>\u001b[0m grid \u001b[39m=\u001b[39m RandomizedSearchCV(estimator \u001b[39m=\u001b[39m clf, param_distributions \u001b[39m=\u001b[39m random_grid, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, refit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m , cv \u001b[39m=\u001b[39m kfold, verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000021?line=2'>3</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, np\u001b[39m.\u001b[39;49mravel(Y_train))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000021?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_params_)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1749\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1748\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1749\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1750\u001b[0m         ParameterSampler(\n\u001b[1;32m   1751\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1752\u001b[0m         )\n\u001b[1;32m   1753\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X_train, np.ravel(Y_train))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M39_HlR_SdEZ",
        "outputId": "e15cbf95-3069-4fef-87be-2185cdcbc653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9960238568588469\n"
          ]
        }
      ],
      "source": [
        "grid_prediction = grid.predict(X_train)\n",
        "score = f1_score(Y_train, grid_prediction)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVt8W7jcS1F2"
      },
      "source": [
        "## PCA (95%)\n",
        "### Used to train: X_train, Y_train \n",
        "### Used to test: X_test, Y_test (if model works well)\n",
        "Note: Validation test set separation already done in training\n",
        "\n",
        "Perform PCA on train set features and separate into x_train and y_train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRRgt96S1F-"
      },
      "source": [
        "Select the number of components such that the amount of variance that needs to be explained is greater than 80% percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qQuVGEV2S1F-",
        "outputId": "aa7ade23-e16e-46fa-cae2-63c10368ce6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21480, 3833)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# perform PCA\n",
        "pca = PCA(n_components = 0.95)\n",
        "traintest_reduced = pca.fit_transform(to_reduce)\n",
        "traintest_reduced = pd.DataFrame(data = traintest_reduced)\n",
        "traintest_reduced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17184, 3833)\n",
            "(17184, 1)\n",
            "(4296, 3833)\n"
          ]
        }
      ],
      "source": [
        "X = traintest_reduced.iloc[0:17184,:]\n",
        "Y = train_set_label\n",
        "submit_set_reduced = traintest_reduced.iloc[17184:,:]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(submit_set_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2cD2b8JS1F_",
        "outputId": "7477530c-491d-42ee-b04d-dc037d963451"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.15, random_state=41)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IzV0tNiSeQy"
      },
      "source": [
        "## Training Ada Boost\n",
        "\n",
        "95% variance\n",
        "\n",
        "{'n_estimators': [10, 580, 1150, 1720, 2290, 2860, 3430, 4000], 'max_features': ['auto', 'sqrt'], 'max_depth': [100, 142, 185, 228, 271, 314, 357, 400], 'bootstrap': [True, False]}\n",
        "\n",
        "\n",
        "4 kfolds\n",
        "\n",
        "Results on X_test:\n",
        "\n",
        "Best:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51owuaQSeQ5",
        "outputId": "75d49b27-087b-4a5a-de8d-ec4caa0dcba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 580, 1150, 1720, 2290, 2860, 3430, 4000], 'algorithm': ['SAMME.R', 'SAMME']}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 4000, num =8)]\n",
        "algorithm = ['SAMME.R','SAMME']\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'algorithm': algorithm,}\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Cwwtq9ZYSeQ6"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 0) # for 4-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbRmkEfFSeQ6",
        "outputId": "596de6a7-5de3-4b97-c5ae-fadf3ce99411"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'AdaBoostClassifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/decision_tree_3.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000031?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m AdaBoostClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000031?line=1'>2</a>\u001b[0m grid \u001b[39m=\u001b[39m RandomizedSearchCV(estimator \u001b[39m=\u001b[39m clf, param_distributions \u001b[39m=\u001b[39m random_grid, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, refit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m , cv \u001b[39m=\u001b[39m kfold, verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/decision_tree_3.ipynb#ch0000031?line=2'>3</a>\u001b[0m grid\u001b[39m.\u001b[39mfit(X, np\u001b[39m.\u001b[39mravel(Y))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AdaBoostClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "clf = AdaBoostClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X, np.ravel(Y))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIspLVVJSeQ6"
      },
      "outputs": [],
      "source": [
        "# grid_prediction = grid.predict(X_train)\n",
        "# score = f1_score(Y_train, grid_prediction)\n",
        "# print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IzV0tNiSeQy"
      },
      "source": [
        "## Training\n",
        "\n",
        "95% variance\n",
        "\n",
        "{'n_estimators': [10, 580, 1150, 1720, 2290, 2860, 3430, 4000], 'max_features': ['auto', 'sqrt'], 'max_depth': [100, 142, 185, 228, 271, 314, 357, 400], 'bootstrap': [True, False]}\n",
        "\n",
        "\n",
        "4 kfolds\n",
        "\n",
        "Results on X_test:\n",
        "\n",
        "Best:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51owuaQSeQ5",
        "outputId": "75d49b27-087b-4a5a-de8d-ec4caa0dcba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [10, 1340, 2670, 4000], 'max_features': ['auto', 'sqrt'], 'max_depth': [100, 200, 300, 400], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "# Number of tree in random forest \n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 4000, num =4)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto','sqrt']\n",
        "#Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# Creating a param grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "            'max_features':max_features,\n",
        "            'max_depth': max_depth,\n",
        "            'bootstrap': bootstrap }\n",
        "\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Cwwtq9ZYSeQ6"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0) # for 4-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbRmkEfFSeQ6",
        "outputId": "596de6a7-5de3-4b97-c5ae-fadf3ce99411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=200, max_features=sqrt, n_estimators=10; total time=  33.8s\n",
            "[CV] END bootstrap=False, max_depth=200, max_features=sqrt, n_estimators=10; total time=  33.9s\n",
            "[CV] END bootstrap=False, max_depth=200, max_features=sqrt, n_estimators=10; total time=  34.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=1340; total time=51.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=1340; total time=51.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=1340; total time=51.8min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=63.8min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=auto, n_estimators=2670; total time=63.8min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=auto, n_estimators=2670; total time=64.0min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=64.1min\n",
            "[CV] END bootstrap=True, max_depth=100, max_features=auto, n_estimators=2670; total time=64.1min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=2670; total time=64.1min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=auto, n_estimators=4000; total time=93.6min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=auto, n_estimators=4000; total time=93.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=True, max_depth=200, max_features=auto, n_estimators=4000; total time=93.9min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=99.3min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=99.1min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=auto, n_estimators=2670; total time=99.9min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=4000; total time=95.3min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=4000; total time=95.6min\n",
            "[CV] END bootstrap=True, max_depth=200, max_features=sqrt, n_estimators=4000; total time=95.8min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=2670; total time=237.7min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=2670; total time=238.0min\n",
            "[CV] END bootstrap=False, max_depth=400, max_features=auto, n_estimators=2670; total time=238.2min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, n_estimators=4000; total time=277.6min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, n_estimators=4000; total time=278.1min\n",
            "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, n_estimators=4000; total time=278.6min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=2670; total time=208.4min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=2670; total time=208.0min\n",
            "[CV] END bootstrap=False, max_depth=300, max_features=sqrt, n_estimators=2670; total time=208.6min\n",
            "{'n_estimators': 10, 'max_features': 'sqrt', 'max_depth': 200, 'bootstrap': False}\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "grid = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, scoring = 'f1', refit = 'accuracy', n_jobs = -1 , cv = kfold, verbose = 2)\n",
        "grid.fit(X, np.ravel(Y))\n",
        "print(grid.best_params_) # gets the best hyper-parameters for random forest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lIspLVVJSeQ6"
      },
      "outputs": [],
      "source": [
        "# grid_prediction = grid.predict(X_train)\n",
        "# score = f1_score(Y_train, grid_prediction)\n",
        "# print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPlo0_RxRQ3y"
      },
      "source": [
        "# TO SUBMIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vk7wtjcca4_r"
      },
      "outputs": [],
      "source": [
        "y_predicted = grid.predict(submit_set_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "w7z46Ug8a6Ab"
      },
      "outputs": [],
      "source": [
        "# y_predicted = svc_model.predict(test_set_features)\n",
        "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
        "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
        "y_predicted.to_csv('skynet_submission2.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "50.0007 ML 1D",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
