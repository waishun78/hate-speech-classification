{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5002)\n",
      "   id  label    0    1    2    3    4    5    6    7  ...  4990  4991  4992  \\\n",
      "0   1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1   2      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2   3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3   4      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4   5      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5   6      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6   7      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7   8      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8   9      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9  10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5002 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = '../Training and Testing sets/train_tfidf_features.csv'\n",
    "train_features = pd.read_csv (filename, header=0)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label    0    1    2    3    4    5    6    7    8  ...  4990  4991  4992  \\\n",
      "id                                                      ...                     \n",
      "1       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "    4993  4994  4995  4996  4997  4998  4999  \n",
      "id                                            \n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "10   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5001 columns]\n"
     ]
    }
   ],
   "source": [
    "train_features.set_index('id', inplace=True, drop=True)\n",
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_helper.kernel_reduction_helper import KernelPCA_reduce\n",
    "\n",
    "# Generate a 100 feature feature set using PCA reduction\n",
    "# print(train_features.iloc[:, 1:].head(10))\n",
    "X = KernelPCA_reduce(train_features.iloc[:, 1:],200)\n",
    "# print(X.head(10))\n",
    "\n",
    "# X = train_features.iloc[:, 10:20].values\n",
    "Y = train_features.iloc[:, 0].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.1, random_state=41)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.1, random_state=41)\n",
    "\n",
    "# X_train is to train data\n",
    "# X_val is for validation of data\n",
    "# X_test is for testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Train a simple model with max_depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17194570135746606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth =3, random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "test_pred_decision_tree = clf.predict(X_val)\n",
    "score = f1_score(Y_val, test_pred_decision_tree)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the f1 score of the decision tree with max depth is extremely low. However, we can try and tweak the max_depth and see if there is a difference is the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.0\n",
      "2 : 0.17691154422788608\n",
      "3 : 0.17194570135746606\n",
      "4 : 0.5\n",
      "5 : 0.4458464773922187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for i in range(1,6):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the optimal depth seems to be at 4 as any further increase in depth will decrease the f1 score on the validation test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.0\n",
      "2 : 0.26379542395693134\n",
      "3 : 0.15727002967359052\n",
      "4 : 0.4033970276008492\n",
      "5 : 0.3295880149812734\n",
      "6 : 0.29183400267737614\n",
      "7 : 0.3649289099526067\n",
      "8 : 0.42784032753326506\n",
      "9 : 0.4191866527632951\n",
      "10 : 0.3949771689497717\n",
      "11 : 0.41401273885350315\n",
      "12 : 0.4444444444444445\n",
      "13 : 0.4339815762538383\n",
      "14 : 0.47316103379721675\n",
      "15 : 0.45004849660523766\n",
      "16 : 0.4133858267716535\n",
      "17 : 0.4409005628517824\n",
      "18 : 0.4524975514201763\n",
      "19 : 0.46389891696750907\n",
      "40 : 0.47635135135135126\n",
      "41 : 0.4877637130801688\n",
      "42 : 0.4451996601529312\n",
      "43 : 0.48444070647603027\n",
      "44 : 0.44079515989628354\n",
      "45 : 0.47675401521555366\n",
      "46 : 0.46559048428207306\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, splitter= \"random\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))\n",
    "\n",
    "for i in range(40,47):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, splitter= \"random\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we used a best random split method instead. We see that the f1 score performance seem to stagnate at around 40-50%. Note that the number of splits were deliberately increased as random split might require more splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy 1 : 0.0\n",
      "Entropy 2 : 0.17691154422788608\n",
      "Entropy 3 : 0.17194570135746606\n",
      "Entropy 4 : 0.501323918799647\n",
      "Entropy 5 : 0.456140350877193\n",
      "Entropy 6 : 0.5136921624173749\n",
      "Entropy 7 : 0.5211786372007368\n",
      "Entropy 8 : 0.48762603116406966\n",
      "Entropy 9 : 0.5\n",
      "log_loss 1 : 0.0\n",
      "log_loss 2 : 0.17691154422788608\n",
      "log_loss 3 : 0.17194570135746606\n",
      "log_loss 4 : 0.501323918799647\n",
      "log_loss 5 : 0.456140350877193\n",
      "log_loss 6 : 0.5136921624173749\n",
      "log_loss 7 : 0.5211786372007368\n",
      "log_loss 8 : 0.48762603116406966\n",
      "log_loss 9 : 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = DecisionTreeClassifier(max_depth =i,criterion=\"entropy\", random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(\"Entropy \"+ str(i)+\" : \"+str(score))\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = DecisionTreeClassifier(max_depth =i,criterion=\"log_loss\", random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(\"log_loss \"+ str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entropy and log_loss also produced similar results as the default gini criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can conclude that neither the criterion nor the number of splits were able to increase the accuracy of the model significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "random_forest = clf.predict(X_val)\n",
    "\n",
    "score = f1_score(Y_val, random_forest)\n",
    "print(str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the max_depth of each tree in the random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.5\n",
      "2 : 0.5\n",
      "3 : 0.5\n",
      "4 : 0.5\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    clf = RandomForestClassifier(max_depth =i)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    random_forest = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, increasing the max_depth doesnot affect the accuracy. Thus, we conclude the max_depth of the tree in the forest is only 1. However, we may suggest changing the number of trees in said forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.5\n",
      "2 : 0.5\n",
      "3 : 0.5\n",
      "4 : 0.5\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    clf = RandomForestClassifier(n_estimators=i)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    random_forest = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tree in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num =5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2','sqrt']\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a param grid\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "            'max_features':max_features,\n",
    "            'max_depth': max_depth,\n",
    "            'bootstrap': bootstrap }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=4)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 4],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=i)\n",
    "\n",
    "rf_Grid = GridSearchCV(estimator = clf, param_grid = random_grid, cv=3, verbose=2, n_jobs = 4)\n",
    "rf_Grid.fit(X_train,Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18429003021148035\n"
     ]
    }
   ],
   "source": [
    "grid_prediction = rf_Grid.predict(X_val)\n",
    "score = f1_score(Y_val, grid_prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV, the parameters performed even worse on the validation dataset, suggesting overfitting to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5108481262327417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "ada_boost_pred = clf.predict(X_val)\n",
    "score = f1_score(Y_val, ada_boost_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.0\n",
      "2 : 0.24327784891165172\n",
      "3 : 0.29404617253948967\n",
      "4 : 0.29404617253948967\n",
      "5 : 0.33886255924170616\n",
      "6 : 0.37602820211515864\n",
      "7 : 0.41014799154334036\n",
      "8 : 0.38513513513513514\n",
      "9 : 0.41914893617021276\n",
      "30 : 0.4808080808080808\n",
      "31 : 0.4803229061553985\n",
      "32 : 0.4924012158054712\n",
      "33 : 0.48088531187122735\n",
      "34 : 0.48040201005025124\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    clf = AdaBoostClassifier(n_estimators=i, random_state=0)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    ada_boost_pred = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, ada_boost_pred)\n",
    "    print(str(i)+\" : \"+str(score))\n",
    "    \n",
    "\n",
    "for i in range(30,35):\n",
    "    clf = AdaBoostClassifier(n_estimators=i, random_state=0)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    ada_boost_pred = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, ada_boost_pred)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5286160249739854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "gradient_boosting_clf = clf.predict(X_val)\n",
    "score = f1_score(Y_val, gradient_boosting_clf)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
