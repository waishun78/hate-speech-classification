{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Machine Learning Model + N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for multi-dimensional array operations\n",
    "import pandas as pd # for reading data from .csv files\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA # for principle component analysis (dimensionality reduction)\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset into training and testing sets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # for getting the best hyper parameters\n",
    "from sklearn.preprocessing import MinMaxScaler # for scaling of data before PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the training set and testing set to variables for easy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../Training and Testing sets/train.csv') # import the training set\n",
    "test_set = pd.read_csv('../../Training and Testing sets/test.csv') # import the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(21480, 5000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_set_label = train_set.loc[:, [\"label\"]]\n",
    "train_words = train_set.drop(['id','label'], axis =1) # train_set_features will not contain the label and id columns\n",
    "test_words = test_set.drop(['id'], axis =1)\n",
    "\n",
    "# print(train_words.head(10))\n",
    "# print(test_words.head(10))\n",
    "\n",
    "frames = [train_words,test_set]\n",
    "to_vector = pd.concat(frames)\n",
    "# print(to_vector.shape)\n",
    "# print(to_vector.head(5))\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(max_features=5000, ngram_range=(2, 2))\n",
    "to_reduce = vectorizer2.fit_transform(to_vector['post'])\n",
    "vectorizer2.get_feature_names_out()\n",
    "print(type(to_reduce))\n",
    "print(to_reduce.shape)\n",
    "print(to_reduce.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9  ...  4990  4991  4992  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5000 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_names = [str(i) for i in range(0, 5000)]\n",
    "\n",
    "df = pd.DataFrame(to_reduce.todense(), columns = features_names)\n",
    "\n",
    "print(df.head(10))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3161</th>\n",
       "      <th>3162</th>\n",
       "      <th>3163</th>\n",
       "      <th>3164</th>\n",
       "      <th>3165</th>\n",
       "      <th>3166</th>\n",
       "      <th>3167</th>\n",
       "      <th>3168</th>\n",
       "      <th>3169</th>\n",
       "      <th>3170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.014941</td>\n",
       "      <td>-0.018820</td>\n",
       "      <td>-0.005642</td>\n",
       "      <td>-0.003160</td>\n",
       "      <td>-0.002568</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>-0.009780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>-0.005175</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>-0.012370</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.014186</td>\n",
       "      <td>-0.019200</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.009602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015710</td>\n",
       "      <td>-0.013595</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.003859</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>-0.006945</td>\n",
       "      <td>-0.005274</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.017163</td>\n",
       "      <td>-0.022316</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>-0.007633</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>-0.009064</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>-0.012863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011127</td>\n",
       "      <td>-0.009287</td>\n",
       "      <td>-0.015277</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>-0.003996</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>-0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>-0.023266</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.045397</td>\n",
       "      <td>0.026235</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>-0.060788</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016985</td>\n",
       "      <td>-0.015716</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>-0.022056</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.027672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014924</td>\n",
       "      <td>-0.021372</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>-0.010231</td>\n",
       "      <td>-0.023476</td>\n",
       "      <td>-0.014723</td>\n",
       "      <td>-0.038557</td>\n",
       "      <td>-0.019589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004645</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>-0.013590</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>-0.010395</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>-0.013922</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>-0.008383</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>-0.002324</td>\n",
       "      <td>-0.009004</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>-0.003648</td>\n",
       "      <td>-0.010939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>-0.002412</td>\n",
       "      <td>-0.003648</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>-0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>-0.044723</td>\n",
       "      <td>0.258589</td>\n",
       "      <td>-0.054264</td>\n",
       "      <td>-0.063301</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>0.044024</td>\n",
       "      <td>-0.108188</td>\n",
       "      <td>0.031136</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>-0.006759</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.012165</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.011416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.015866</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>-0.016841</td>\n",
       "      <td>-0.017031</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.022620</td>\n",
       "      <td>-0.008357</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>-0.002911</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>-0.008610</td>\n",
       "      <td>0.011284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>-0.002988</td>\n",
       "      <td>-0.020983</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>-0.008987</td>\n",
       "      <td>-0.004996</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.015085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>-0.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>-0.014537</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>-0.006679</td>\n",
       "      <td>-0.004940</td>\n",
       "      <td>-0.011150</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>-0.008697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003371</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.007381</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.001324</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.005495</td>\n",
       "      <td>-0.009025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21480 rows × 3171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.014941 -0.018820 -0.005642 -0.003160 -0.002568 -0.007729  0.002250   \n",
       "1     -0.014186 -0.019200 -0.006263  0.000862 -0.003506 -0.007469  0.001890   \n",
       "2     -0.017163 -0.022316  0.002719 -0.005427 -0.007365 -0.007633  0.003539   \n",
       "3     -0.022529 -0.008018  0.026099 -0.023266  0.017116 -0.045397  0.026235   \n",
       "4     -0.014924 -0.021372 -0.019956 -0.015842  0.004789 -0.010231 -0.023476   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21475 -0.013922 -0.020059 -0.008383 -0.007273 -0.002324 -0.009004  0.000398   \n",
       "21476 -0.044723  0.258589 -0.054264 -0.063301  0.021689  0.044024 -0.108188   \n",
       "21477 -0.004025 -0.015866 -0.008282 -0.016841 -0.017031  0.001657 -0.013370   \n",
       "21478 -0.002988 -0.020983 -0.008548 -0.008987 -0.004996 -0.008239 -0.004295   \n",
       "21479 -0.014537 -0.022021 -0.009940 -0.006679 -0.004940 -0.011150 -0.002942   \n",
       "\n",
       "           7         8         9     ...      3161      3162      3163  \\\n",
       "0      0.003700  0.000928 -0.009780  ...  0.013244 -0.005175  0.009710   \n",
       "1      0.003623 -0.001053 -0.009602  ... -0.015710 -0.013595 -0.008706   \n",
       "2     -0.009064 -0.001119 -0.012863  ...  0.011127 -0.009287 -0.015277   \n",
       "3      0.158389 -0.060788  0.173287  ...  0.016985 -0.015716 -0.015158   \n",
       "4     -0.014723 -0.038557 -0.019589  ... -0.004645 -0.000388  0.002716   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21475  0.005826 -0.003648 -0.010939  ...  0.001368  0.002188 -0.002412   \n",
       "21476  0.031136  0.020324 -0.008220  ...  0.005639 -0.006759  0.004200   \n",
       "21477 -0.022620 -0.008357  0.004496  ...  0.005200  0.008936  0.011855   \n",
       "21478  0.001019 -0.009165 -0.015085  ...  0.004153  0.015697  0.006593   \n",
       "21479 -0.002248  0.004112 -0.008697  ... -0.003371  0.001611 -0.003333   \n",
       "\n",
       "           3164      3165      3166      3167      3168      3169      3170  \n",
       "0      0.001519  0.025120 -0.012370 -0.003109  0.009207  0.019224  0.010008  \n",
       "1     -0.003859 -0.008753  0.019053 -0.006945 -0.005274 -0.004522  0.003430  \n",
       "2      0.000964  0.003077  0.007442  0.007025 -0.003996  0.002996 -0.004377  \n",
       "3      0.005747  0.007912 -0.022056  0.010080  0.005163  0.021510  0.027672  \n",
       "4     -0.013590  0.005778  0.002614 -0.005142  0.008499 -0.010395  0.002315  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21475 -0.003648 -0.000143  0.000720  0.000854  0.002170  0.001211 -0.001956  \n",
       "21476 -0.010559 -0.001686  0.000380  0.004091 -0.012165 -0.000709 -0.011416  \n",
       "21477 -0.002911  0.006393  0.001920  0.006204  0.013062 -0.008610  0.011284  \n",
       "21478  0.004705  0.015448  0.004966  0.012480 -0.003510  0.011379 -0.003338  \n",
       "21479 -0.007381 -0.000821 -0.018692 -0.001324 -0.007470 -0.005495 -0.009025  \n",
       "\n",
       "[21480 rows x 3171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform PCA\n",
    "pca = PCA(n_components = 0.90)\n",
    "train_test_reduced = pca.fit_transform(df)\n",
    "train_test_reduced = pd.DataFrame(data = train_test_reduced)\n",
    "train_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 3171)\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0 -0.014941 -0.018820 -0.005642 -0.003160 -0.002568 -0.007729  0.002250   \n",
      "1 -0.014186 -0.019200 -0.006263  0.000862 -0.003506 -0.007469  0.001890   \n",
      "2 -0.017163 -0.022316  0.002719 -0.005427 -0.007365 -0.007633  0.003539   \n",
      "3 -0.022529 -0.008018  0.026099 -0.023266  0.017116 -0.045397  0.026235   \n",
      "4 -0.014924 -0.021372 -0.019956 -0.015842  0.004789 -0.010231 -0.023476   \n",
      "\n",
      "       7         8         9     ...      3161      3162      3163      3164  \\\n",
      "0  0.003700  0.000928 -0.009780  ...  0.013244 -0.005175  0.009710  0.001519   \n",
      "1  0.003623 -0.001053 -0.009602  ... -0.015710 -0.013595 -0.008706 -0.003859   \n",
      "2 -0.009064 -0.001119 -0.012863  ...  0.011127 -0.009287 -0.015277  0.000964   \n",
      "3  0.158389 -0.060788  0.173287  ...  0.016985 -0.015716 -0.015158  0.005747   \n",
      "4 -0.014723 -0.038557 -0.019589  ... -0.004645 -0.000388  0.002716 -0.013590   \n",
      "\n",
      "       3165      3166      3167      3168      3169      3170  \n",
      "0  0.025120 -0.012370 -0.003109  0.009207  0.019224  0.010008  \n",
      "1 -0.008753  0.019053 -0.006945 -0.005274 -0.004522  0.003430  \n",
      "2  0.003077  0.007442  0.007025 -0.003996  0.002996 -0.004377  \n",
      "3  0.007912 -0.022056  0.010080  0.005163  0.021510  0.027672  \n",
      "4  0.005778  0.002614 -0.005142  0.008499 -0.010395  0.002315  \n",
      "\n",
      "[5 rows x 3171 columns]\n",
      "(17184, 1)\n",
      "   label\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "(4296, 3171)\n",
      "           0         1         2         3         4         5         6     \\\n",
      "17184 -0.014708 -0.021014 -0.008364 -0.006591 -0.002845 -0.009863  0.001399   \n",
      "17185 -0.015362 -0.025439 -0.009632 -0.013491  0.005554 -0.002100  0.000802   \n",
      "17186  0.238595  0.011343 -0.008875 -0.004157  0.004127 -0.005860  0.012303   \n",
      "17187 -0.007673 -0.019987 -0.002547 -0.005937 -0.001489 -0.008387 -0.003949   \n",
      "17188 -0.026422  0.019428  0.000847  0.273835 -0.072977  0.023109 -0.080246   \n",
      "\n",
      "           7         8         9     ...      3161      3162      3163  \\\n",
      "17184  0.006346  0.000179 -0.009160  ... -0.002002  0.001790  0.014426   \n",
      "17185 -0.028046  0.236955  0.053421  ...  0.005585 -0.014071  0.008348   \n",
      "17186 -0.000016 -0.014186 -0.007367  ... -0.005596  0.002532 -0.006715   \n",
      "17187  0.002990  0.014221 -0.009004  ... -0.001172  0.007947 -0.004307   \n",
      "17188 -0.024212 -0.028819  0.011511  ... -0.016153 -0.006385 -0.006628   \n",
      "\n",
      "           3164      3165      3166      3167      3168      3169      3170  \n",
      "17184  0.015710 -0.007408 -0.015647  0.007010 -0.018751  0.006922 -0.000027  \n",
      "17185  0.008068 -0.004020 -0.003871  0.014223 -0.001075  0.000420  0.014829  \n",
      "17186  0.002084  0.000706 -0.006367 -0.005646 -0.005721 -0.010051 -0.002115  \n",
      "17187 -0.012560  0.005207 -0.019245  0.042654 -0.006514  0.019168 -0.022996  \n",
      "17188  0.013129 -0.007946  0.001959  0.012185 -0.013129  0.013244 -0.008896  \n",
      "\n",
      "[5 rows x 3171 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_test_reduced.iloc[0:17184,:]\n",
    "Y_train = train_set_label\n",
    "\n",
    "X_test = train_test_reduced.iloc[17184:21480,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head(5))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train.head(5))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV to find interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/AdaBoost_ngram.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost_ngram.ipynb#ch0000011?line=8'>9</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mgrid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, refit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost_ngram.ipynb#ch0000011?line=9'>10</a>\u001b[0m \u001b[39m# execute the grid search\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost_ngram.ipynb#ch0000011?line=10'>11</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mfit(X_train, np\u001b[39m.\u001b[39;49mravel(Y_train))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost_ngram.ipynb#ch0000011?line=11'>12</a>\u001b[0m \u001b[39m# summarize the best score and configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost_ngram.ipynb#ch0000011?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [100, 500]\n",
    "grid['learning_rate'] = [0.1, 1.0, 2.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_macro', refit = 'f1_macro')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, np.ravel(Y_train))\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Test Results (0.66135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels for the test dataset based on the model with the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = svc_model.predict(test_set_features)\n",
    "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
    "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
    "y_predicted.to_csv('ada_boost_ngram.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis for train_set (95% variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21480 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[21480 rows x 5000 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine test and train\n",
    "frames = [train_set_features,test_set_features]\n",
    "to_reduce = pd.concat(frames)\n",
    "\n",
    "# scale the dataset before PCA\n",
    "scaler = MinMaxScaler()\n",
    "traintest_to_reduce = scaler.fit_transform(to_reduce)\n",
    "\n",
    "# perform PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "train_test_reduced = pca.fit_transform(traintest_to_reduce)\n",
    "train_test_reduced = pd.DataFrame(data = traintest_to_reduce)\n",
    "train_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5000)\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n",
      "(17184, 1)\n",
      "   label\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "(4296, 5000)\n",
      "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_test_reduced.iloc[0:17184,:]\n",
    "Y_train = train_set_label\n",
    "\n",
    "X_test = train_test_reduced.iloc[17184:21480,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head(5))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train.head(5))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV to find interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_macro', refit = 'f1_macro')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, np.ravel(Y_train))\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels for the test dataset based on the model with the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = svc_model.predict(test_set_features)\n",
    "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
    "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
    "y_predicted.to_csv('skynet_submission_new.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
