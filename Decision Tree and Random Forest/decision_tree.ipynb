{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from df_helper.reduction_helper import PCA_reduce\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5002)\n",
      "   id  label    0    1    2    3    4    5    6    7  ...  4990  4991  4992  \\\n",
      "0   1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1   2      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2   3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3   4      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4   5      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5   6      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6   7      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7   8      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8   9      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9  10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5002 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = '../Training and Testing sets/train_tfidf_features.csv'\n",
    "train_features = pd.read_csv (filename, header=0)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label    0    1    2    3    4    5    6    7    8  ...  4990  4991  4992  \\\n",
      "id                                                      ...                     \n",
      "1       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "    4993  4994  4995  4996  4997  4998  4999  \n",
      "id                                            \n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "10   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5001 columns]\n"
     ]
    }
   ],
   "source": [
    "train_features.set_index('id', inplace=True, drop=True)\n",
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 100 feature feature set using PCA reduction\n",
    "# print(train_features.iloc[:, 1:].head(10))\n",
    "X = PCA_reduce(train_features.iloc[:, 1:],200)\n",
    "# print(X.head(10))\n",
    "\n",
    "# X = train_features.iloc[:, 10:20].values\n",
    "Y = train_features.iloc[:, 0].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.1, random_state=41)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.1, random_state=41)\n",
    "\n",
    "# X_train is to train data\n",
    "# X_val is for validation of data\n",
    "# X_test is for testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = train_features.iloc[:, 0].values.reshape(-1,1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_features, Y, test_size=.1, random_state=41)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Train a simple model with max_depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17194570135746606\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth =3, random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "test_pred_decision_tree = clf.predict(X_val)\n",
    "score = f1_score(Y_val, test_pred_decision_tree)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the f1 score of the decision tree with max depth is extremely low. However, we can try and tweak the max_depth and see if there is a difference is the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.0\n",
      "2 : 0.17691154422788608\n",
      "3 : 0.17194570135746606\n",
      "4 : 0.4995571302037201\n",
      "5 : 0.4430512016718913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,6):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the optimal depth seems to be at 4 as any further increase in depth will decrease the f1 score on the validation test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.02368866328257191\n",
      "2 : 0.11690363349131123\n",
      "3 : 0.2103825136612022\n",
      "4 : 0.308252427184466\n",
      "5 : 0.33537331701346385\n",
      "6 : 0.30341340075853346\n",
      "7 : 0.3730684326710817\n",
      "8 : 0.41530054644808745\n",
      "9 : 0.45540398740818466\n",
      "10 : 0.455078125\n",
      "11 : 0.4270152505446623\n",
      "12 : 0.44536940686784604\n",
      "13 : 0.45813282001924927\n",
      "14 : 0.4298874104401228\n",
      "15 : 0.4194214876033058\n",
      "16 : 0.4898710865561694\n",
      "17 : 0.45209302325581396\n",
      "18 : 0.4694656488549618\n",
      "19 : 0.45107176141658906\n",
      "40 : 0.4507512520868114\n",
      "41 : 0.4542372881355933\n",
      "42 : 0.46761984861227923\n",
      "43 : 0.49626556016597506\n",
      "44 : 0.48205128205128206\n",
      "45 : 0.47952218430034127\n",
      "46 : 0.48123980424143553\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, splitter= \"random\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))\n",
    "\n",
    "for i in range(40,47):\n",
    "    clf = DecisionTreeClassifier(max_depth =i, splitter= \"random\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we used a best random split method instead. We see that the f1 score performance seem to stagnate at around 40-50%. Note that the number of splits were deliberately increased as random split might require more splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy 1 : 0.0\n",
      "Entropy 2 : 0.17691154422788608\n",
      "Entropy 3 : 0.17691154422788608\n",
      "Entropy 4 : 0.5035211267605635\n",
      "Entropy 5 : 0.4569055036344756\n",
      "Entropy 6 : 0.5229357798165138\n",
      "Entropy 7 : 0.5122615803814714\n",
      "Entropy 8 : 0.49363369245837413\n",
      "Entropy 9 : 0.49195837275307475\n",
      "log_loss 1 : 0.0\n",
      "log_loss 2 : 0.17691154422788608\n",
      "log_loss 3 : 0.17691154422788608\n",
      "log_loss 4 : 0.5035211267605635\n",
      "log_loss 5 : 0.4569055036344756\n",
      "log_loss 6 : 0.5229357798165138\n",
      "log_loss 7 : 0.5122615803814714\n",
      "log_loss 8 : 0.49363369245837413\n",
      "log_loss 9 : 0.49195837275307475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = DecisionTreeClassifier(max_depth =i,criterion=\"entropy\", random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(\"Entropy \"+ str(i)+\" : \"+str(score))\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = DecisionTreeClassifier(max_depth =i,criterion=\"log_loss\", random_state = 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    test_pred_decision_tree = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(\"log_loss \"+ str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entropy and log_loss also produced similar results as the default gini criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can conclude that neither the criterion nor the number of splits were able to increase the accuracy of the model significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "random_forest = clf.predict(X_val)\n",
    "\n",
    "score = f1_score(Y_val, random_forest)\n",
    "print(str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the max_depth of each tree in the random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.49195837275307475\n",
      "2 : 0.49195837275307475\n",
      "3 : 0.49195837275307475\n",
      "4 : 0.49195837275307475\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    clf = RandomForestClassifier(max_depth =i)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    random_forest = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  label    0    1    2    3    4    5    6    7  ...  4990  4991  \\\n",
      "8130    8131      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "17077  17078      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "14105  14106      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "16427  16428      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "12464  12465      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "2743    2744      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "4619    4620      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "16384  16385      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "14181  14182      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "12285  12286      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "\n",
      "       4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "8130    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17077   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "14105   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "16427   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "12464   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2743    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4619    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "16384   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "14181   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "12285   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5002 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1000 features, but RandomForestClassifier is expecting 5002 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/decision_tree.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000047?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(max_depth \u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000047?line=1'>2</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, Y_train\u001b[39m.\u001b[39mravel())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000047?line=2'>3</a>\u001b[0m random_forest \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_val)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000047?line=3'>4</a>\u001b[0m score \u001b[39m=\u001b[39m f1_score(Y_val, test_pred_decision_tree)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000047?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m : \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(score))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:832\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    812\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 832\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    834\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    872\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    873\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 874\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    876\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    877\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 605\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1000 features, but RandomForestClassifier is expecting 5002 features as input."
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth =3)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "random_forest = clf.predict(X_val)\n",
    "score = f1_score(Y_val, test_pred_decision_tree)\n",
    "print(str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, increasing the max_depth doesnot affect the accuracy. Thus, we conclude the max_depth of the tree in the forest is only 1. However, we may suggest changing the number of trees in said forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.49195837275307475\n",
      "2 : 0.49195837275307475\n",
      "3 : 0.49195837275307475\n",
      "4 : 0.49195837275307475\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    clf = RandomForestClassifier(n_estimators=i)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    random_forest = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tree in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num =5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2','sqrt']\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a param grid\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "            'max_features':max_features,\n",
    "            'max_depth': max_depth,\n",
    "            'bootstrap': bootstrap }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=10; total time=   0.1s\n",
      "\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=20; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=30; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=40; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=log2, n_estimators=50; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=2, max_features=sqrt, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=20; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=30; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=40; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=log2, n_estimators=50; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=40; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=10; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=4, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=30; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=40; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=log2, n_estimators=50; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=30; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=40; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=log2, n_estimators=50; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=20; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=30; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=40; total time=   2.1s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [2, 4],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=4)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=4), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 4],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators=i)\n",
    "\n",
    "rf_Grid = GridSearchCV(estimator = clf, param_grid = random_grid, cv=3, verbose=2, n_jobs = 4)\n",
    "rf_Grid.fit(X_train,Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724659606656581\n"
     ]
    }
   ],
   "source": [
    "grid_prediction = rf_Grid.predict(X_val)\n",
    "score = f1_score(Y_val, grid_prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV, the parameters performed even worse on the validation dataset, suggesting overfitting to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5020161290322581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "ada_boost_pred = clf.predict(X_val)\n",
    "score = f1_score(Y_val, ada_boost_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.0\n",
      "2 : 0.24327784891165172\n",
      "3 : 0.29404617253948967\n",
      "4 : 0.29404617253948967\n",
      "5 : 0.33886255924170616\n",
      "6 : 0.37602820211515864\n",
      "7 : 0.41014799154334036\n",
      "8 : 0.38513513513513514\n",
      "9 : 0.41914893617021276\n",
      "30 : 0.472986748216106\n",
      "31 : 0.47648261758691207\n",
      "32 : 0.486322188449848\n",
      "33 : 0.48521916411824667\n",
      "34 : 0.4831804281345566\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    clf = AdaBoostClassifier(n_estimators=i, random_state=0)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    ada_boost_pred = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, ada_boost_pred)\n",
    "    print(str(i)+\" : \"+str(score))\n",
    "    \n",
    "\n",
    "for i in range(30,35):\n",
    "    clf = AdaBoostClassifier(n_estimators=i, random_state=0)\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    ada_boost_pred = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, ada_boost_pred)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5156576200417536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "gradient_boosting_clf = clf.predict(X_val)\n",
    "score = f1_score(Y_val, gradient_boosting_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2 at PCA with higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label    0    1    2    3    4    5    6    7    8  ...  4990  4991  4992  \\\n",
      "0      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5001 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = '../Training and Testing sets/train_tfidf_features.csv'\n",
    "train_features = pd.read_csv (filename, header=0)\n",
    "\n",
    "# Remove index\n",
    "train_features = train_features.iloc[:, 1:]\n",
    "print(train_features.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/decision_tree.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000037?line=0'>1</a>\u001b[0m \u001b[39m# Generate a 100 feature feature set using PCA reduction\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000037?line=1'>2</a>\u001b[0m \u001b[39m# print(train_features.iloc[:, 1:].head(10))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000037?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m PCA_reduce(train_features\u001b[39m.\u001b[39;49miloc[:,\u001b[39m1\u001b[39;49m:],\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/df_helper/reduction_helper.py:6\u001b[0m, in \u001b[0;36mPCA_reduce\u001b[0;34m(features, components)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPCA_reduce\u001b[39m(features,components):\n\u001b[1;32m      5\u001b[0m     pca_n \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39mcomponents)\n\u001b[0;32m----> 6\u001b[0m     principalComponents_N \u001b[39m=\u001b[39m pca_n\u001b[39m.\u001b[39;49mfit_transform(features)\n\u001b[1;32m      7\u001b[0m     principalDf_N \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data \u001b[39m=\u001b[39m principalComponents_N)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m principalDf_N\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:433\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    412\u001b[0m     \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    434\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    437\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_full(X, n_components)\n\u001b[1;32m    484\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 485\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_truncated(X, n_components, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_svd_solver)\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnrecognized svd_solver=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n\u001b[1;32m    489\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:606\u001b[0m, in \u001b[0;36mPCA._fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    602\u001b[0m     U, Vt \u001b[39m=\u001b[39m svd_flip(U[:, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], Vt[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    604\u001b[0m \u001b[39melif\u001b[39;00m svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    605\u001b[0m     \u001b[39m# sign flipping is done inside\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m randomized_svd(\n\u001b[1;32m    607\u001b[0m         X,\n\u001b[1;32m    608\u001b[0m         n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[1;32m    609\u001b[0m         n_oversamples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_oversamples,\n\u001b[1;32m    610\u001b[0m         n_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterated_power,\n\u001b[1;32m    611\u001b[0m         power_iteration_normalizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower_iteration_normalizer,\n\u001b[1;32m    612\u001b[0m         flip_sign\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    613\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    614\u001b[0m     )\n\u001b[1;32m    616\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_ \u001b[39m=\u001b[39m n_samples, n_features\n\u001b[1;32m    617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponents_ \u001b[39m=\u001b[39m Vt\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/extmath.py:396\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n\u001b[1;32m    393\u001b[0m     \u001b[39m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     M \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 396\u001b[0m Q \u001b[39m=\u001b[39m randomized_range_finder(\n\u001b[1;32m    397\u001b[0m     M,\n\u001b[1;32m    398\u001b[0m     size\u001b[39m=\u001b[39;49mn_random,\n\u001b[1;32m    399\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[1;32m    400\u001b[0m     power_iteration_normalizer\u001b[39m=\u001b[39;49mpower_iteration_normalizer,\n\u001b[1;32m    401\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    404\u001b[0m \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    405\u001b[0m B \u001b[39m=\u001b[39m safe_sparse_dot(Q\u001b[39m.\u001b[39mT, M)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/extmath.py:245\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    241\u001b[0m         Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mqr(safe_sparse_dot(A\u001b[39m.\u001b[39mT, Q), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meconomic\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Sample the range of A using by linear projection of Q\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# Extract an orthonormal basis\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mqr(safe_sparse_dot(A, Q), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meconomic\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m Q\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/extmath.py:155\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m--> 155\u001b[0m     sparse\u001b[39m.\u001b[39;49missparse(a)\n\u001b[1;32m    156\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    157\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    158\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m ):\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/scipy/sparse/_base.py:1294\u001b[0m, in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1291\u001b[0m             \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m-> 1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misspmatrix\u001b[39m(x):\n\u001b[1;32m   1295\u001b[0m     \u001b[39m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \n\u001b[1;32m   1297\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate a 100 feature feature set using PCA reduction\n",
    "# print(train_features.iloc[:, 1:].head(10))\n",
    "\n",
    "X = PCA_reduce(train_features.iloc[:,1:],1000)\n",
    "# print(X.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6    \\\n",
      "0     -0.083198 -0.016048 -0.010595 -0.001964 -0.013779 -0.010988 -0.009680   \n",
      "1     -0.068421 -0.043649 -0.018443 -0.008228 -0.000051 -0.043176  0.127322   \n",
      "2     -0.080171 -0.044642 -0.015342 -0.008697 -0.010481 -0.057562  0.075615   \n",
      "3      0.028601 -0.040406  0.002784  0.007087  0.000462 -0.031219 -0.137443   \n",
      "4      0.255054 -0.113418 -0.019237 -0.021468 -0.040033 -0.007000 -0.035961   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "17179  0.075930  0.078879  0.167305 -0.099091  0.304845  0.037761 -0.022524   \n",
      "17180 -0.072104 -0.019731 -0.014655 -0.005451 -0.005682 -0.012314  0.005987   \n",
      "17181  0.002079 -0.041786 -0.016886 -0.008919 -0.018063 -0.020859  0.006685   \n",
      "17182  0.091355 -0.055903 -0.008473 -0.017559 -0.002191 -0.013549 -0.012348   \n",
      "17183 -0.040612  0.093708 -0.039986 -0.025745 -0.032479  0.004735  0.001654   \n",
      "\n",
      "            7         8         9    ...       990       991       992  \\\n",
      "0     -0.007521 -0.022370 -0.023418  ...  0.001454  0.030020 -0.008960   \n",
      "1      0.010281  0.014349 -0.005607  ... -0.024093  0.020699 -0.013234   \n",
      "2      0.115412  0.111499  0.070551  ...  0.014571  0.010396 -0.002043   \n",
      "3      0.114581 -0.013428  0.077351  ... -0.007504  0.018902  0.006955   \n",
      "4      0.008656 -0.026048 -0.003353  ... -0.008185 -0.000723  0.018765   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "17179  0.018488 -0.015024 -0.006993  ...  0.015385  0.001310 -0.019331   \n",
      "17180 -0.009017 -0.003208 -0.014674  ... -0.003457 -0.007646 -0.012310   \n",
      "17181 -0.006915 -0.017608  0.010784  ... -0.000731 -0.006611  0.036341   \n",
      "17182 -0.003721 -0.017070 -0.010729  ... -0.000363  0.002804  0.003718   \n",
      "17183  0.001413 -0.004797 -0.021880  ...  0.016334 -0.014243  0.003238   \n",
      "\n",
      "            993       994       995       996       997       998       999  \n",
      "0     -0.011997 -0.028202 -0.000434 -0.017298 -0.007467  0.009172 -0.003942  \n",
      "1      0.007700  0.009161 -0.016500  0.036092 -0.022806  0.007718  0.025696  \n",
      "2      0.006393  0.004560  0.000445 -0.001357  0.010875 -0.006986  0.016838  \n",
      "3     -0.012565 -0.000479  0.028904 -0.031450 -0.001934  0.006763 -0.018401  \n",
      "4     -0.019251 -0.008650  0.021971  0.010140  0.003555  0.021245 -0.023182  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17179 -0.008700  0.026117 -0.008673  0.032732  0.005327 -0.012909  0.003912  \n",
      "17180 -0.014655  0.011305 -0.003886  0.006372  0.003735 -0.001223 -0.019548  \n",
      "17181 -0.010886 -0.024028  0.049922  0.007652  0.005852 -0.002524  0.037625  \n",
      "17182 -0.002874  0.008149  0.000572 -0.002139 -0.003338 -0.001008 -0.001728  \n",
      "17183 -0.022875 -0.009694  0.012246  0.018219 -0.004271  0.018985 -0.013759  \n",
      "\n",
      "[17184 rows x 1000 columns]\n",
      "(17184, 1000)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "(17184, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = train_features.iloc[:, 0].values.reshape(-1,1)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.1, random_state=41)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4654731457800511\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 30, random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "test_pred_decision_tree = clf.predict(X_val)\n",
    "score = f1_score(Y_val, test_pred_decision_tree)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 : 0.4654731457800511\n",
      "35 : 0.4654731457800511\n",
      "40 : 0.4654731457800511\n",
      "45 : 0.4654731457800511\n",
      "50 : 0.4654731457800511\n",
      "55 : 0.4654731457800511\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,60,5):\n",
    "    clf = RandomForestClassifier(max_depth = i )\n",
    "    clf.fit(X_train, Y_train.ravel())\n",
    "    random_forest = clf.predict(X_val)\n",
    "    score = f1_score(Y_val, test_pred_decision_tree)\n",
    "    print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 : 0.4654731457800511\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth = 10 )\n",
    "clf.fit(X_train, Y_train.ravel())\n",
    "random_forest = clf.predict(X_val)\n",
    "score = f1_score(Y_val, test_pred_decision_tree)\n",
    "print(str(i)+\" : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tree in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num =50)]\n",
    "# Criterion for split\n",
    "criterion = ['gini','entropy']\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 1000, num =400)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]\n",
    "# Out of Bag Score\n",
    "oob_score = [True,False]\n",
    "# Run in parallel\n",
    "n_jobs = [-1]\n",
    "# Reuse the solution of the previous call to fit and add more estimators to the ensemble\n",
    "warm_start = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a param grid\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "            'criterion':criterion,\n",
    "            'max_depth': max_depth,\n",
    "            'bootstrap': bootstrap,\n",
    "            \"oob_score\": oob_score,\n",
    "            \"n_jobs\": n_jobs,\n",
    "            \"warm_start\": warm_start }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/decision_tree.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000041?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000041?line=1'>2</a>\u001b[0m rf_Grid \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m clf, param_grid \u001b[39m=\u001b[39m random_grid,n_jobs\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/Library/CloudStorage/OneDrive-SingaporeUniversityofTechnologyandDesign/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/decision_tree.ipynb#ch0000041?line=2'>3</a>\u001b[0m rf_Grid\u001b[39m.\u001b[39;49mfit(X_train,Y_train\u001b[39m.\u001b[39;49mravel())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "rf_Grid = GridSearchCV(estimator = clf, param_grid = random_grid,n_jobs= -1, cv = 3, scoring = 'f1')\n",
    "rf_Grid.fit(X_train,Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_prediction = rf_Grid.predict(X_val)\n",
    "score = f1_score(Y_val, grid_prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
