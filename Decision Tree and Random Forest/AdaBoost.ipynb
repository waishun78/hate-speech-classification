{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for multi-dimensional array operations\n",
    "import pandas as pd # for reading data from .csv files\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA # for principle component analysis (dimensionality reduction)\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset into training and testing sets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # for getting the best hyper parameters\n",
    "from sklearn.preprocessing import MinMaxScaler # for scaling of data before PCA\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the training set and testing set to variables for easy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../Training and Testing sets/train_tfidf_features.csv') # import the training set\n",
    "test_set = pd.read_csv('../../Training and Testing sets/test_tfidf_features.csv') # import the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17184, 5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_label = train_set.loc[:, [\"label\"]]\n",
    "features_names = [str(i) for i in range(0, 5000)]\n",
    "train_set_features = train_set.loc[:, features_names] # train_set_features will not contain the label and id columns\n",
    "test_set_features = test_set.loc[:, features_names] # test_set_features will not contain the label and id columns\n",
    "\n",
    "train_set_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis for train_set (90% variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21480 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[21480 rows x 5000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine test and train\n",
    "frames = [train_set_features,test_set_features]\n",
    "to_reduce = pd.concat(frames)\n",
    "\n",
    "# scale the dataset before PCA\n",
    "scaler = MinMaxScaler()\n",
    "traintest_to_reduce = scaler.fit_transform(to_reduce)\n",
    "\n",
    "# perform PCA\n",
    "pca = PCA(n_components = 0.90)\n",
    "train_test_reduced = pca.fit_transform(traintest_to_reduce)\n",
    "train_test_reduced = pd.DataFrame(data = traintest_to_reduce)\n",
    "train_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5000)\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n",
      "(17184, 1)\n",
      "   label\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "(4296, 5000)\n",
      "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_test_reduced.iloc[0:17184,:]\n",
    "Y_train = train_set_label\n",
    "\n",
    "X_test = train_test_reduced.iloc[17184:21480,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head(5))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train.head(5))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning with Hyperparameter (Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 722, 1435, 2148, 2861, 3574, 4287, 5000], 'algorithm': ['SAMME.R', 'SAMME']}\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# Number of tree in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 5000, num =8)]\n",
    "\n",
    "learning_rate = [0.1,1,2,5]\n",
    "\n",
    "algorithm = ['SAMME.R','SAMME']\n",
    "\n",
    "# Creating a param grid\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "            'algorithm': algorithm,}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=10; total time=   7.5s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=10; total time=   7.5s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=10; total time=   7.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/AdaBoost.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000031?line=0'>1</a>\u001b[0m kfold \u001b[39m=\u001b[39m StratifiedKFold(n_splits \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m# for 3-fold cross validation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000031?line=1'>2</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(AdaBoostClassifier(), param_grid \u001b[39m=\u001b[39m random_grid, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, refit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m , cv \u001b[39m=\u001b[39m kfold, verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000031?line=2'>3</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, np\u001b[39m.\u001b[39;49mravel(Y_train)) \u001b[39m# training the model using the best hyper-parameters\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000031?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlgorithm must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m iboost \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    161\u001b[0m         iboost, X, y, sample_weight, random_state\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:568\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:577\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 577\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    579\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0) # for 3-fold cross validation\n",
    "grid = GridSearchCV(AdaBoostClassifier(), param_grid = random_grid, scoring = 'f1_macro', refit = 'f1_macro', n_jobs = 1 , cv = kfold, verbose = 2)\n",
    "grid.fit(X_train, np.ravel(Y_train)) # training the model using the best hyper-parameters\n",
    "print(grid.best_params_) # gets the best hyper-parameters for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: n_features\n",
    "Evaluating the performance of different weak learners (different Decision Tree Classifiers with a range of max_depth) used in the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.676 (0.009)\n",
      ">50 0.691 (0.008)\n",
      ">100 0.697 (0.008)\n",
      ">500 0.705 (0.009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "config_context() got an unexpected keyword argument 'pairwise_dist_chunk_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 215, in __call__\n    with config_context(**self.config):\n  File \"/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py\", line 281, in helper\n    return _GeneratorContextManager(func, args, kwds)\n  File \"/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py\", line 103, in __init__\n    self.gen = func(*args, **kwds)\nTypeError: config_context() got an unexpected keyword argument 'pairwise_dist_chunk_size'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/AdaBoost.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=21'>22</a>\u001b[0m results, names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(), \u001b[39mlist\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=23'>24</a>\u001b[0m \t\u001b[39m# evaluate the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=24'>25</a>\u001b[0m \tscores \u001b[39m=\u001b[39m evaluate_model(model, X_train, np\u001b[39m.\u001b[39;49mravel(Y_train))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=25'>26</a>\u001b[0m \t\u001b[39m# store the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=26'>27</a>\u001b[0m \tresults\u001b[39m.\u001b[39mappend(scores)\n",
      "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/AdaBoost.ipynb Cell 15\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=12'>13</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=13'>14</a>\u001b[0m \u001b[39m# evaluate the model and collect the results\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=14'>15</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(model, X, y, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000033?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: config_context() got an unexpected keyword argument 'pairwise_dist_chunk_size'"
     ]
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_ntree_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [10, 50, 100, 500, 1000, 5000]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = AdaBoostClassifier(n_estimators=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_ntree_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train, np.ravel(Y_train))\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Weak Learners\n",
    "Evaluating the performance of different weak learners (different Decision Tree Classifiers with a range of max_depth) used in the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.806 (0.041)\n",
      ">2 0.863 (0.028)\n",
      ">3 0.865 (0.030)\n",
      ">4 0.895 (0.029)\n",
      ">5 0.913 (0.022)\n",
      ">6 0.921 (0.024)\n",
      ">7 0.925 (0.026)\n",
      ">8 0.929 (0.024)\n",
      ">9 0.931 (0.026)\n",
      ">10 0.926 (0.024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_weaklearner_models():\n",
    "\tmodels = dict()\n",
    "\t# explore depths from 1 to 10\n",
    "\tfor i in range(1,11):\n",
    "\t\t# define base model\n",
    "\t\tbase = DecisionTreeClassifier(max_depth=i)\n",
    "\t\t# define ensemble model\n",
    "\t\tmodels[str(i)] = AdaBoostClassifier(base_estimator=base)\n",
    "\treturn models\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_weaklearner_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train, np.ravel(Y_train))\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Learning Rate\n",
    "Evaluating the performance of learning rateson the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.100 0.767 (0.049)\n",
      ">0.200 0.786 (0.042)\n",
      ">0.300 0.802 (0.040)\n",
      ">0.400 0.798 (0.037)\n",
      ">0.500 0.805 (0.042)\n",
      ">0.600 0.795 (0.031)\n",
      ">0.700 0.799 (0.035)\n",
      ">0.800 0.801 (0.033)\n",
      ">0.900 0.805 (0.032)\n",
      ">1.000 0.806 (0.041)\n",
      ">1.100 0.801 (0.037)\n",
      ">1.200 0.800 (0.030)\n",
      ">1.300 0.799 (0.041)\n",
      ">1.400 0.793 (0.041)\n",
      ">1.500 0.790 (0.040)\n",
      ">1.600 0.775 (0.034)\n",
      ">1.700 0.767 (0.054)\n",
      ">1.800 0.768 (0.040)\n",
      ">1.900 0.736 (0.047)\n",
      ">2.000 0.682 (0.048)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_learningrate_model():\n",
    "\tmodels = dict()\n",
    "\t# explore learning rates from 0.1 to 2 in 0.1 increments\n",
    "\tfor i in np.arange(0.1, 2.1, 0.1):\n",
    "\t\tkey = '%.3f' % i\n",
    "\t\tmodels[key] = AdaBoostClassifier(learning_rate=i)\n",
    "\treturn models\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_learningrate_model()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train, np.ravel(Y_train))\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Explore with Alternate Algorithms\n",
    "Evaluating the performance of different algorithms besides decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(probability=True, kernel='linear')\n",
    "lr=LogisticRegression()\n",
    "models=[svc,lr]\n",
    "for i in models:\n",
    "  model = AdaBoostClassifier(base_estimator=i)\n",
    "  # evaluate the model\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  n_scores = cross_val_score(model, X_train, np.ravel(Y_train), scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "  # report performance\n",
    "  results.append(n_scores)\n",
    "  names.append(i)\n",
    "  print('Accuracy for {} : %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV to find interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign (Archive)/SUTD_Y2/Term_5/Machine Learning | 50.007/500007_ML_proj/Decision Tree and Random Forest/AdaBoost.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000023?line=8'>9</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mgrid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, refit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000023?line=9'>10</a>\u001b[0m \u001b[39m# execute the grid search\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000023?line=10'>11</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mfit(X_train, np\u001b[39m.\u001b[39mravel(Y_train))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000023?line=11'>12</a>\u001b[0m \u001b[39m# summarize the best score and configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/waishun/OneDrive-SingaporeUniversityofTechnologyandDesign%20%28Archive%29/SUTD_Y2/Term_5/Machine%20Learning%20%7C%2050.007/500007_ML_proj/Decision%20Tree%20and%20Random%20Forest/AdaBoost.ipynb#ch0000023?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_macro', refit = 'f1_macro')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, np.ravel(Y_train))\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Test Results (0.66135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels for the test dataset based on the model with the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = svc_model.predict(test_set_features)\n",
    "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
    "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
    "y_predicted.to_csv('skynet_submission_new.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis for train_set (95% variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21480 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "21475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21476   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21477   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21478   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "21479   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[21480 rows x 5000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine test and train\n",
    "frames = [train_set_features,test_set_features]\n",
    "to_reduce = pd.concat(frames)\n",
    "\n",
    "# scale the dataset before PCA\n",
    "scaler = MinMaxScaler()\n",
    "traintest_to_reduce = scaler.fit_transform(to_reduce)\n",
    "\n",
    "# perform PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "train_test_reduced = pca.fit_transform(traintest_to_reduce)\n",
    "train_test_reduced = pd.DataFrame(data = traintest_to_reduce)\n",
    "train_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5000)\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n",
      "(17184, 1)\n",
      "   label\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "(4296, 5000)\n",
      "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
      "17184   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17185   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17186   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17187   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "17188   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_test_reduced.iloc[0:17184,:]\n",
    "Y_train = train_set_label\n",
    "\n",
    "X_test = train_test_reduced.iloc[17184:21480,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head(5))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train.head(5))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV to find interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_macro', refit = 'f1_macro')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, np.ravel(Y_train))\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels for the test dataset based on the model with the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = svc_model.predict(test_set_features)\n",
    "y_predicted = pd.DataFrame(y_predicted, columns = ['label']) # convert y_predicted from nparray to pandas dataframe\n",
    "y_predicted.insert(loc = 0, column = 'id', value = [i for i in range(17185, 17185 + 4296)]) # insert a column of the ids, starting from 17185\n",
    "y_predicted.to_csv('skynet_submission_new.csv', index = False) # output the predicted labels to ./skynet_submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
